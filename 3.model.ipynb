{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeaf5992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 1024])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.left = torch.nn.Linear(1024, 2048, bias=False)\n",
    "        self.right = torch.nn.Linear(1024, 2048, bias=False)\n",
    "        self.out = torch.nn.Linear(2048, 1024, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x -> [b, lens, 1024]\n",
    "\n",
    "        #[b, lens, 1024] -> [b, lens, 2048]\n",
    "        left = torch.nn.functional.gelu(self.left(x), approximate='tanh')\n",
    "\n",
    "        #[b, lens, 1024] -> [b, lens, 2048]\n",
    "        right = self.right(x)\n",
    "\n",
    "        #[b, lens, 2048] -> [b, lens, 1024]\n",
    "        return self.out(left * right)\n",
    "\n",
    "\n",
    "MLP()(torch.randn(2, 15, 1024)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d9236c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 64])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Norm(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.zeros(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #两种情况\n",
    "        #x -> [b, lens, dim]\n",
    "        #x -> [b, heads, lens, dim]\n",
    "\n",
    "        #形状不变\n",
    "        x = x * (x.pow(2).mean(-1, keepdim=True) + 1e-6).rsqrt()\n",
    "        x = x * (1.0 + self.weight)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "Norm(64)(torch.randn(2, 15, 64)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0cfa214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 1024])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Atten(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.q = torch.nn.Linear(1024, 2048, bias=False)\n",
    "        self.k = torch.nn.Linear(1024, 1024, bias=False)\n",
    "        self.v = torch.nn.Linear(1024, 1024, bias=False)\n",
    "        self.out = torch.nn.Linear(2048, 1024, bias=False)\n",
    "\n",
    "        self.norm_q = Norm(dim=256)\n",
    "        self.norm_k = Norm(dim=256)\n",
    "\n",
    "        #[128]\n",
    "        inv_freq = 1.0 / (1e4**(torch.arange(0, 256, 2).float() / 256))\n",
    "        #[128] -> [1, 128, 1]\n",
    "        inv_freq = inv_freq.reshape(1, 128, 1).float()\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        #x -> [b, lens, 1024]\n",
    "        #mask -> [b, 1, lens, lens]\n",
    "\n",
    "        b, lens = x.shape[0], x.shape[1]\n",
    "\n",
    "        #[b, lens, 1024] -> [b, lens, 2048] -> [b, lens, 8, 256] -> [b, 8, lens, 256]\n",
    "        q = self.q(x).reshape(b, lens, -1, 256).transpose(1, 2)\n",
    "        #[b, lens, 1024] -> [b, lens, 1024] -> [b, lens, 4, 256] -> [b, 4, lens, 256]\n",
    "        k = self.k(x).reshape(b, lens, -1, 256).transpose(1, 2)\n",
    "        #[b, lens, 1024] -> [b, lens, 1024] -> [b, lens, 4, 256] -> [b, 4, lens, 256]\n",
    "        v = self.v(x).reshape(b, lens, -1, 256).transpose(1, 2)\n",
    "\n",
    "        q = self.norm_q(q)\n",
    "        k = self.norm_k(k)\n",
    "\n",
    "        #[b, 1, lens, 256], [b, 1, lens, 256]\n",
    "        with torch.no_grad():\n",
    "            #[1, 128, 1] -> [b, 128, 1]\n",
    "            inv_freq = self.inv_freq.repeat(x.shape[0], 1, 1)\n",
    "\n",
    "            #[lens]\n",
    "            position_ids = torch.arange(x.shape[1], device=x.device)\n",
    "            #[lens] -> [1, 1, lens]\n",
    "            position_ids = position_ids.reshape(1, 1, -1).float()\n",
    "\n",
    "            #[b, 128, 1] * [1, 1, lens] -> [b, 128, lens] -> [b, lens, 128]\n",
    "            emb = (inv_freq @ position_ids).transpose(1, 2)\n",
    "            #[b, lens, 128] -> [b, lens, 256]\n",
    "            emb = torch.cat((emb, emb), dim=2)\n",
    "\n",
    "            #[b, 1, lens, 256], [b, 1, lens, 256]\n",
    "            cos, sin = emb.cos().unsqueeze(1), emb.sin().unsqueeze(1)\n",
    "\n",
    "        def rotate(x):\n",
    "            left = -x[:, :, :, x.shape[3] // 2:]\n",
    "            right = x[:, :, :, :x.shape[3] // 2]\n",
    "            return torch.cat((left, right), dim=3)\n",
    "\n",
    "        #[b, 8, lens, 256]\n",
    "        q = (q * cos) + (rotate(q) * sin)\n",
    "        #[b, 4, lens, 256]\n",
    "        k = (k * cos) + (rotate(k) * sin)\n",
    "\n",
    "        def repeat_kv(x):\n",
    "            x = x.unsqueeze(2).repeat(1, 1, 2, 1, 1)\n",
    "            return x.reshape(x.shape[0], x.shape[1] * 2, x.shape[3],\n",
    "                             x.shape[4])\n",
    "\n",
    "        #[b, 8, lens, 256]\n",
    "        k = repeat_kv(k)\n",
    "        #[b, 8, lens, 256]\n",
    "        v = repeat_kv(v)\n",
    "\n",
    "        #[b, 8, lens, 256] * [b, 8, 256, lens] -> [b, 8, lens, lens]\n",
    "        out = q @ k.transpose(2, 3)\n",
    "        out = out * 256**-0.5 + mask\n",
    "        #[b, 8, lens, lens] * [b, 8, lens, 256] -> [b, 8, lens, 256]\n",
    "        out = out.softmax(dim=3) @ v\n",
    "\n",
    "        #out = torch.nn.functional.scaled_dot_product_attention(q,k,v,attn_mask=mask,scale=256**-0.5)\n",
    "\n",
    "        #[b, 8, lens, 256] -> [b, lens, 8, 256] -> [b, lens, 2048]\n",
    "        out = out.transpose(1, 2).reshape(b, lens, -1)\n",
    "        #[b, lens, 2048] -> [b, lens, 1024]\n",
    "        out = self.out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "Atten()(torch.randn(2, 15, 1024), torch.randint(0, 2, [2, 1, 15, 15])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b11d5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.self_attn = Atten()\n",
    "        self.mlp = MLP()\n",
    "        self.norm1 = Norm(1024)\n",
    "        self.norm2 = Norm(1024)\n",
    "        self.norm3 = Norm(1024)\n",
    "        self.norm4 = Norm(1024)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        #x -> [b, lens, 1024]\n",
    "        #mask -> [b, 1, lens, lens]\n",
    "\n",
    "        #形状不变\n",
    "        res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.self_attn(x, mask)\n",
    "        x = self.norm2(x) + res\n",
    "\n",
    "        #形状不变\n",
    "        res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.norm4(x) + res\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "Decoder()(torch.randn(2, 15, 1024), torch.randint(0, 2, [2, 1, 15, 15])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de11f267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 15, 15])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mask(attention_mask):\n",
    "    lens = attention_mask.shape[1]\n",
    "\n",
    "    #[lens, lens]\n",
    "    mask = torch.full((lens, lens),\n",
    "                      fill_value=-1e32,\n",
    "                      device=attention_mask.device)\n",
    "\n",
    "    #对角线和对角线以下归零\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "\n",
    "    #[lens, lens] -> [1, 1, lens, lens]\n",
    "    mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    #[b, lens] -> [b, 1, 1, lens]\n",
    "    attention_mask = attention_mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "    #[1, 1, lens, lens] + [b, 1, 1, lens] -> [b, 1, lens, lens]\n",
    "    padding_mask = mask + attention_mask\n",
    "\n",
    "    #[b, 1, lens, lens]\n",
    "    mask = mask.masked_fill(padding_mask == 0, -1e32)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "get_mask(torch.randint(0, 2, [2, 15])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8746dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemma3Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, pad_token_id):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = torch.nn.Embedding(vocab_size, 1024, pad_token_id)\n",
    "        self.layers = torch.nn.ModuleList([Decoder() for _ in range(16)])\n",
    "        self.norm = Norm(1024)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        #input_ids -> [b, lens]\n",
    "        #attention_mask -> [b, lens]\n",
    "\n",
    "        #[b, lens] -> [b, lens, 1024]\n",
    "        x = self.embed(input_ids) * 1024**0.5\n",
    "\n",
    "        #[b, 1, lens, lens]\n",
    "        mask = get_mask(attention_mask)\n",
    "\n",
    "        for i in self.layers:\n",
    "            x = i(x, mask)\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "# Gemma3Model(16, 0)(torch.randint(0, 16, [2, 15]), torch.randint(0, 2,\n",
    "#                                                                 [2, 15])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f3626f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Gemma3Actor(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, pad_token_id):\n",
    "        super().__init__()\n",
    "        self.model = Gemma3Model(vocab_size, pad_token_id)\n",
    "        self.lm_head = torch.nn.Linear(1024, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        #input_ids -> [b, lens]\n",
    "        #attention_mask -> [b, lens]\n",
    "        #labels -> [b, lens]\n",
    "\n",
    "        #[b, lens] -> [b, lens, 1024]\n",
    "        logits = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #[b, lens, 1024] -> [b, lens, vocab_size]\n",
    "        logits = self.lm_head(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            labels = torch.nn.functional.pad(labels, (0, 1), value=-100)\n",
    "            labels = labels[..., 1:]\n",
    "\n",
    "            loss = torch.nn.functional.cross_entropy(logits.flatten(end_dim=1),\n",
    "                                                     labels.flatten(),\n",
    "                                                     ignore_index=-100,\n",
    "                                                     reduction='mean')\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "\n",
    "# Gemma3Actor(16, 0)(input_ids=torch.randint(0, 16, [2, 15]),\n",
    "#                    attention_mask=torch.randint(0, 2, [2, 15]),\n",
    "#                    labels=torch.randint(0, 16, [2, 15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b8dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model_actor, input_ids, pad_token_id, eos_token_id):\n",
    "    max_length = 128\n",
    "    attention_mask = (input_ids != pad_token_id).long()\n",
    "\n",
    "    _, logits = model_actor(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    predict = logits[:, -1].argmax(1, keepdim=True)\n",
    "\n",
    "    input_ids = torch.cat((input_ids, predict), 1)\n",
    "\n",
    "    if input_ids.shape[1] >= max_length:\n",
    "        return input_ids\n",
    "\n",
    "    ends = (input_ids == eos_token_id).sum(1) > 0\n",
    "\n",
    "    if ends.all():\n",
    "        return input_ids\n",
    "\n",
    "    return generate(model_actor, input_ids, pad_token_id, eos_token_id)\n",
    "\n",
    "\n",
    "# generate(model_actor=Gemma3Actor(16, 0),\n",
    "#          input_ids=torch.randint(0, 16, [2, 15]),\n",
    "#          pad_token_id=0,\n",
    "#          eos_token_id=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc56abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemma3Critic(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, pad_token_id, eos_token_id):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = Gemma3Model(vocab_size, pad_token_id)\n",
    "        self.eos_token_id = eos_token_id\n",
    "        self.score = torch.nn.Linear(1024, 1, bias=False)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        #input_ids -> [b, lens]\n",
    "        #attention_mask -> [b, lens]\n",
    "        #labels -> [b, 1]\n",
    "\n",
    "        #[b, lens] -> [b, lens, 1024]\n",
    "        logits = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #[b, lens, 1024] -> [b, lens, 1]\n",
    "        logits = self.score(logits)\n",
    "\n",
    "        ends = []\n",
    "        for i in input_ids:\n",
    "            i = i.tolist()\n",
    "            end = len(i) - 1\n",
    "            if self.eos_token_id in i:\n",
    "                end = i.index(self.eos_token_id)\n",
    "            ends.append(end)\n",
    "\n",
    "        logits = logits[range(input_ids.shape[0]), ends]\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.functional.mse_loss(logits.flatten(),\n",
    "                                                labels.flatten())\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "\n",
    "# Gemma3Critic(16, 0, 1)(torch.randint(0, 16, [2, 15]),\n",
    "#                        torch.randint(0, 2, [2, 15]), torch.randn(2, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
