{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeaf5992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 1024])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.left = torch.nn.Linear(1024, 2048, bias=False)\n",
    "        self.right = torch.nn.Linear(1024, 2048, bias=False)\n",
    "        self.out = torch.nn.Linear(2048, 1024, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x -> [b, lens, 1024]\n",
    "\n",
    "        #[b, lens, 1024] -> [b, lens, 2048]\n",
    "        left = torch.nn.functional.gelu(self.left(x), approximate='tanh')\n",
    "\n",
    "        #[b, lens, 1024] -> [b, lens, 2048]\n",
    "        right = self.right(x)\n",
    "\n",
    "        #[b, lens, 2048] -> [b, lens, 1024]\n",
    "        return self.out(left * right)\n",
    "\n",
    "\n",
    "MLP()(torch.randn(2, 15, 1024)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d9236c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 64])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Norm(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.zeros(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #两种情况\n",
    "        #x -> [b, lens, dim]\n",
    "        #x -> [b, heads, lens, dim]\n",
    "\n",
    "        #形状不变\n",
    "        x = x * (x.pow(2).mean(-1, keepdim=True) + 1e-6).rsqrt()\n",
    "        x = x * (1.0 + self.weight)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "Norm(64)(torch.randn(2, 15, 64)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0cfa214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 1024])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Atten(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.q = torch.nn.Linear(1024, 2048, bias=False)\n",
    "        self.k = torch.nn.Linear(1024, 1024, bias=False)\n",
    "        self.v = torch.nn.Linear(1024, 1024, bias=False)\n",
    "        self.out = torch.nn.Linear(2048, 1024, bias=False)\n",
    "\n",
    "        self.norm_q = Norm(dim=256)\n",
    "        self.norm_k = Norm(dim=256)\n",
    "\n",
    "        #[128]\n",
    "        inv_freq = 1.0 / (1e4**(torch.arange(0, 256, 2).float() / 256))\n",
    "        #[128] -> [1, 128, 1]\n",
    "        inv_freq = inv_freq.reshape(1, 128, 1).float()\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        #x -> [b, lens, 1024]\n",
    "        #mask -> [b, 1, lens, lens]\n",
    "\n",
    "        b, lens = x.shape[0], x.shape[1]\n",
    "\n",
    "        #[b, lens, 1024] -> [b, lens, 2048] -> [b, lens, 8, 256] -> [b, 8, lens, 256]\n",
    "        q = self.q(x).reshape(b, lens, -1, 256).transpose(1, 2)\n",
    "        #[b, lens, 1024] -> [b, lens, 1024] -> [b, lens, 4, 256] -> [b, 4, lens, 256]\n",
    "        k = self.k(x).reshape(b, lens, -1, 256).transpose(1, 2)\n",
    "        #[b, lens, 1024] -> [b, lens, 1024] -> [b, lens, 4, 256] -> [b, 4, lens, 256]\n",
    "        v = self.v(x).reshape(b, lens, -1, 256).transpose(1, 2)\n",
    "\n",
    "        q = self.norm_q(q)\n",
    "        k = self.norm_k(k)\n",
    "\n",
    "        #[b, 1, lens, 256], [b, 1, lens, 256]\n",
    "        with torch.no_grad():\n",
    "            #[1, 128, 1] -> [b, 128, 1]\n",
    "            inv_freq = self.inv_freq.repeat(x.shape[0], 1, 1)\n",
    "\n",
    "            #[lens]\n",
    "            position_ids = torch.arange(x.shape[1], device=x.device)\n",
    "            #[lens] -> [1, 1, lens]\n",
    "            position_ids = position_ids.reshape(1, 1, -1).float()\n",
    "\n",
    "            #[b, 128, 1] * [1, 1, lens] -> [b, 128, lens] -> [b, lens, 128]\n",
    "            emb = (inv_freq @ position_ids).transpose(1, 2)\n",
    "            #[b, lens, 128] -> [b, lens, 256]\n",
    "            emb = torch.cat((emb, emb), dim=2)\n",
    "\n",
    "            #[b, 1, lens, 256], [b, 1, lens, 256]\n",
    "            cos, sin = emb.cos().unsqueeze(1), emb.sin().unsqueeze(1)\n",
    "\n",
    "        def rotate(x):\n",
    "            left = -x[:, :, :, x.shape[3] // 2:]\n",
    "            right = x[:, :, :, :x.shape[3] // 2]\n",
    "            return torch.cat((left, right), dim=3)\n",
    "\n",
    "        #[b, 8, lens, 256]\n",
    "        q = (q * cos) + (rotate(q) * sin)\n",
    "        #[b, 4, lens, 256]\n",
    "        k = (k * cos) + (rotate(k) * sin)\n",
    "\n",
    "        def repeat_kv(x):\n",
    "            x = x.unsqueeze(2).repeat(1, 1, 2, 1, 1)\n",
    "            return x.reshape(x.shape[0], x.shape[1] * 2, x.shape[3],\n",
    "                             x.shape[4])\n",
    "\n",
    "        #[b, 8, lens, 256]\n",
    "        k = repeat_kv(k)\n",
    "        #[b, 8, lens, 256]\n",
    "        v = repeat_kv(v)\n",
    "\n",
    "        #[b, 8, lens, 256] * [b, 8, 256, lens] -> [b, 8, lens, lens]\n",
    "        out = q @ k.transpose(2, 3)\n",
    "        out = out * 256**-0.5 + mask\n",
    "        #[b, 8, lens, lens] * [b, 8, lens, 256] -> [b, 8, lens, 256]\n",
    "        out = out.softmax(dim=3) @ v\n",
    "\n",
    "        #out = torch.nn.functional.scaled_dot_product_attention(q,k,v,attn_mask=mask,scale=256**-0.5)\n",
    "\n",
    "        #[b, 8, lens, 256] -> [b, lens, 8, 256] -> [b, lens, 2048]\n",
    "        out = out.transpose(1, 2).reshape(b, lens, -1)\n",
    "        #[b, lens, 2048] -> [b, lens, 1024]\n",
    "        out = self.out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "Atten()(torch.randn(2, 15, 1024), torch.randint(0, 2, [2, 1, 15, 15])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b11d5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.self_attn = Atten()\n",
    "        self.mlp = MLP()\n",
    "        self.norm1 = Norm(1024)\n",
    "        self.norm2 = Norm(1024)\n",
    "        self.norm3 = Norm(1024)\n",
    "        self.norm4 = Norm(1024)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        #x -> [b, lens, 1024]\n",
    "        #mask -> [b, 1, lens, lens]\n",
    "\n",
    "        #形状不变\n",
    "        res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.self_attn(x, mask)\n",
    "        x = self.norm2(x) + res\n",
    "\n",
    "        #形状不变\n",
    "        res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.norm4(x) + res\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "Decoder()(torch.randn(2, 15, 1024), torch.randint(0, 2, [2, 1, 15, 15])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de11f267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 15, 15])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mask(attention_mask):\n",
    "    lens = attention_mask.shape[1]\n",
    "\n",
    "    #[lens, lens]\n",
    "    mask = torch.full((lens, lens),\n",
    "                      fill_value=-1e32,\n",
    "                      device=attention_mask.device)\n",
    "\n",
    "    #对角线和对角线以下归零\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "\n",
    "    #[lens, lens] -> [1, 1, lens, lens]\n",
    "    mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    #[b, lens] -> [b, 1, 1, lens]\n",
    "    attention_mask = attention_mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "    #[1, 1, lens, lens] + [b, 1, 1, lens] -> [b, 1, lens, lens]\n",
    "    padding_mask = mask + attention_mask\n",
    "\n",
    "    #[b, 1, lens, lens]\n",
    "    mask = mask.masked_fill(padding_mask == 0, -1e32)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "get_mask(torch.randint(0, 2, [2, 15])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8746dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 1024])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Gemma3Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, pad_token_id):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = torch.nn.Embedding(vocab_size, 1024, pad_token_id)\n",
    "        self.layers = torch.nn.ModuleList([Decoder() for _ in range(16)])\n",
    "        self.norm = Norm(1024)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        #input_ids -> [b, lens]\n",
    "        #attention_mask -> [b, lens]\n",
    "\n",
    "        #[b, lens] -> [b, lens, 1024]\n",
    "        x = self.embed(input_ids) * 1024**0.5\n",
    "\n",
    "        #[b, 1, lens, lens]\n",
    "        mask = get_mask(attention_mask)\n",
    "\n",
    "        for i in self.layers:\n",
    "            x = i(x, mask)\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "Gemma3Model(16, 0)(torch.randint(0, 16, [2, 15]), torch.randint(0, 2,\n",
    "                                                                [2, 15])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f3626f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.8809, grad_fn=<NllLossBackward0>),\n",
       " tensor([[[ 4.9931e-01,  2.6358e-01, -6.9108e-01, -8.2092e-01, -3.5185e-01,\n",
       "           -1.1082e-01,  6.2080e-02, -7.7483e-01, -1.2577e-01,  3.1631e-01,\n",
       "            2.6910e-02, -2.7915e-01, -2.5486e-02, -7.3420e-02, -1.3707e+00,\n",
       "            1.0384e+00],\n",
       "          [ 4.0725e-01,  8.3875e-02,  4.6034e-01, -3.0774e-01, -7.2191e-01,\n",
       "           -6.1969e-01, -5.2242e-01, -1.5075e-01, -1.0387e+00,  8.4529e-01,\n",
       "           -2.0267e-01,  3.5437e-01,  4.0266e-01,  4.3016e-02,  3.5819e-01,\n",
       "            5.5118e-01],\n",
       "          [ 1.0875e-01, -1.3081e+00,  9.5620e-01,  3.8039e-01, -3.7686e-01,\n",
       "            4.5391e-01, -9.2286e-01,  4.3188e-01,  6.1821e-01, -3.4398e-01,\n",
       "           -9.0507e-02,  3.6013e-01, -3.7015e-01, -3.0767e-01,  3.1152e-03,\n",
       "           -5.1721e-01],\n",
       "          [-2.6928e-01, -3.5677e-01, -1.1369e+00, -4.9205e-01, -1.2345e-02,\n",
       "            6.1982e-01,  5.4395e-01, -6.5105e-01, -1.1177e+00, -7.6442e-01,\n",
       "           -1.4860e-01,  2.3622e-01, -3.9530e-01, -4.1193e-01,  2.3961e-01,\n",
       "           -5.7746e-01],\n",
       "          [ 1.8820e-01, -9.2739e-02, -1.3194e-01, -6.3932e-01, -5.1747e-01,\n",
       "           -2.1360e-01, -4.9367e-01, -1.4197e-01,  3.8855e-01, -2.4828e-01,\n",
       "           -9.6633e-01, -1.7395e-02, -6.0034e-01,  5.5284e-02,  7.0197e-01,\n",
       "           -4.4210e-01],\n",
       "          [-9.1376e-01, -2.8633e-01,  4.7013e-01,  4.2854e-01, -1.0891e-01,\n",
       "            4.0858e-01, -1.1219e-01,  4.5184e-01,  1.4702e-01,  3.8252e-01,\n",
       "            3.2976e-01,  1.7093e-01,  4.4281e-01, -3.1782e-01, -1.4071e+00,\n",
       "           -4.5292e-02],\n",
       "          [ 8.4187e-01,  1.9836e-01, -7.6918e-01, -6.3876e-01, -8.0292e-01,\n",
       "            3.9477e-01, -1.8446e-01, -6.7750e-01,  6.7772e-01,  1.2707e-01,\n",
       "           -4.4612e-01, -5.9553e-02,  9.2443e-01, -5.7616e-01,  2.1651e-02,\n",
       "           -9.9155e-01],\n",
       "          [-2.9526e-01, -3.0057e-01, -1.2386e+00, -5.1809e-01,  7.5162e-03,\n",
       "            5.6206e-01,  4.7150e-01, -5.9916e-01, -1.0076e+00, -6.4187e-01,\n",
       "           -1.4288e-02,  2.3869e-01, -5.3058e-01, -3.8353e-01,  2.2705e-01,\n",
       "           -5.1175e-01],\n",
       "          [ 1.0084e+00, -3.3252e-01,  1.3511e-01,  1.1647e-01,  1.3351e-01,\n",
       "            2.6278e-01, -5.9257e-01,  1.2826e+00,  4.5394e-01, -7.6785e-02,\n",
       "            4.7097e-02, -3.0320e-01,  7.0416e-02,  6.1734e-01,  7.4228e-01,\n",
       "            1.5126e-01],\n",
       "          [-1.1401e+00, -6.7823e-01, -6.1662e-01,  6.5036e-01, -7.8164e-01,\n",
       "            4.2962e-01, -4.1042e-01, -6.5213e-01, -4.0978e-01, -2.2578e-01,\n",
       "            3.9386e-01, -5.3128e-02, -7.6988e-01, -1.2501e+00,  5.8872e-01,\n",
       "           -3.7206e-01],\n",
       "          [-1.1155e+00, -7.2039e-01, -6.0935e-01,  6.6377e-01, -7.6318e-01,\n",
       "            4.4476e-01, -4.1620e-01, -6.5895e-01, -3.9187e-01, -2.0938e-01,\n",
       "            4.0146e-01, -5.0530e-02, -7.3651e-01, -1.2441e+00,  6.3370e-01,\n",
       "           -3.8899e-01],\n",
       "          [ 1.0662e+00, -4.1079e-01,  1.2897e-01,  1.4836e-01,  1.6495e-01,\n",
       "            3.1260e-01, -5.8776e-01,  1.2591e+00,  4.8044e-01, -5.7531e-02,\n",
       "           -1.1038e-02, -3.6182e-01,  1.8218e-01,  5.7319e-01,  7.6373e-01,\n",
       "            1.1511e-01],\n",
       "          [-4.3490e-01, -8.0002e-01, -4.7358e-01, -5.6985e-01,  4.4412e-01,\n",
       "           -1.7350e-01,  9.8442e-01, -7.2693e-01,  6.1671e-01,  4.1361e-01,\n",
       "           -7.7053e-02,  6.6910e-01,  8.9883e-01,  4.8391e-01, -1.0393e+00,\n",
       "            1.1142e+00],\n",
       "          [ 2.3139e+00, -1.0801e+00,  1.2602e-02,  1.6127e-01,  5.5139e-01,\n",
       "           -9.3879e-02, -1.2207e+00,  7.4158e-01,  2.7444e-02, -1.3310e-01,\n",
       "           -6.5407e-01,  5.5745e-01,  6.4040e-01,  6.6174e-02,  1.3452e-02,\n",
       "           -9.5843e-02],\n",
       "          [ 2.3036e+00, -1.0730e+00,  1.7580e-02,  1.6843e-01,  5.6388e-01,\n",
       "           -8.3758e-02, -1.2196e+00,  7.3876e-01,  1.4947e-02, -1.2232e-01,\n",
       "           -6.5273e-01,  5.6324e-01,  6.6030e-01,  5.5773e-02,  2.2963e-02,\n",
       "           -9.3181e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00],\n",
       "          [-3.3832e-01, -7.6306e-01, -1.2381e+00, -3.8668e-01,  4.6054e-01,\n",
       "           -1.9259e-01,  6.5191e-01,  8.2368e-01, -4.8219e-01, -4.3986e-01,\n",
       "           -9.3735e-01,  9.9966e-01,  3.7014e-01, -2.7948e-01, -3.5345e-01,\n",
       "           -1.2075e-01],\n",
       "          [ 3.8559e-01,  5.8931e-02,  4.6831e-01, -2.9801e-01, -7.3724e-01,\n",
       "           -6.4338e-01, -4.1724e-01, -3.3758e-02, -1.0003e+00,  1.0342e+00,\n",
       "           -2.4536e-01,  4.0274e-01,  2.6121e-01,  3.5426e-02,  3.8097e-01,\n",
       "            4.9685e-01],\n",
       "          [-1.6982e+00, -5.4396e-01, -9.5676e-01,  7.3012e-01, -5.3904e-01,\n",
       "           -2.2394e-01,  3.4316e-01, -4.9758e-01,  1.3164e+00,  3.3543e-02,\n",
       "            2.6893e-02, -1.9430e-01,  1.6057e-01,  2.2816e-01,  1.7170e+00,\n",
       "           -1.9642e-01],\n",
       "          [ 4.0646e-01,  1.9158e-01, -4.7000e-01, -6.3357e-02,  5.9442e-01,\n",
       "            1.4079e+00, -2.3052e-01, -1.0098e+00,  4.2368e-01, -9.4885e-02,\n",
       "           -7.2165e-01,  1.1541e+00, -1.5122e-01, -4.8928e-01, -1.3772e-01,\n",
       "           -5.6906e-01],\n",
       "          [-4.6828e-01, -5.4113e-01, -5.2838e-01, -5.7813e-01,  3.3227e-01,\n",
       "           -1.3192e-01,  1.1700e+00, -6.0466e-01,  4.0990e-01,  3.5935e-01,\n",
       "            1.4236e-02,  7.6992e-01,  7.9973e-01,  2.0195e-01, -1.0666e+00,\n",
       "            1.1487e+00],\n",
       "          [ 2.9721e-01,  6.7987e-01, -1.4903e+00,  4.4089e-02, -6.0568e-01,\n",
       "            2.8110e-01,  3.1071e-01, -4.2450e-03, -1.1530e-01, -7.7190e-01,\n",
       "            3.9761e-01,  3.2264e-02,  2.3114e-01, -1.4168e+00, -2.4522e-01,\n",
       "            1.1140e+00],\n",
       "          [-1.2444e+00, -5.0172e-01, -7.1403e-01,  7.5317e-01, -7.5240e-01,\n",
       "            5.8952e-01, -2.9789e-01, -4.8740e-01, -4.1641e-01, -1.9511e-01,\n",
       "            4.3866e-01,  1.7763e-01, -7.9626e-01, -1.5074e+00,  5.4216e-01,\n",
       "           -3.1178e-01],\n",
       "          [ 9.2735e-01,  4.4110e-01, -9.0400e-01, -6.0159e-01, -7.3315e-01,\n",
       "            6.1013e-01, -1.2625e-01, -6.6409e-01,  5.3063e-01,  2.1747e-01,\n",
       "           -3.4435e-01,  4.2476e-02,  9.2970e-01, -7.5470e-01,  3.6418e-02,\n",
       "           -8.9941e-01],\n",
       "          [ 9.8747e-01, -2.1912e-01,  1.3579e-01,  2.4192e-01,  6.1751e-02,\n",
       "            4.5650e-01, -5.0748e-01,  1.3469e+00,  4.0350e-01, -2.2704e-02,\n",
       "           -3.0046e-02, -2.6129e-01,  8.3975e-02,  3.9216e-01,  8.1547e-01,\n",
       "            1.6792e-01],\n",
       "          [-2.5479e-01, -7.1987e-01, -1.3007e+00, -3.7393e-01,  4.8084e-01,\n",
       "           -2.7443e-02,  5.3684e-01,  8.2829e-01, -5.6531e-01, -4.0760e-01,\n",
       "           -9.1789e-01,  9.7462e-01,  3.6264e-01, -4.2694e-01, -3.5661e-01,\n",
       "            1.5041e-02],\n",
       "          [-4.6451e-01,  2.2227e-01, -2.4029e-01,  9.0562e-02,  1.5861e-01,\n",
       "           -4.6427e-01, -1.1285e-01,  2.8079e-01, -8.1526e-01, -1.0466e+00,\n",
       "           -1.7713e-01,  2.9464e-01, -1.0951e+00, -2.5495e-01, -1.0348e+00,\n",
       "            5.9881e-01],\n",
       "          [ 1.7284e-01, -2.1897e-02, -1.1942e-01, -7.5632e-01, -5.0852e-01,\n",
       "           -1.0605e-01, -4.1617e-01, -1.3313e-01,  3.4832e-01, -2.1259e-01,\n",
       "           -9.5732e-01,  4.8782e-02, -6.6266e-01, -2.1394e-02,  6.6282e-01,\n",
       "           -3.0523e-01],\n",
       "          [ 9.3162e-01, -2.9587e-01,  1.8189e-01,  1.0319e-01,  1.6773e-01,\n",
       "            3.8485e-01, -5.7030e-01,  1.2506e+00,  3.7621e-01,  4.4291e-02,\n",
       "            4.0061e-03, -2.4157e-01,  5.3847e-02,  3.9334e-01,  7.1315e-01,\n",
       "            3.2766e-02],\n",
       "          [-1.2215e+00, -5.3213e-01, -6.0349e-01,  6.2398e-01, -7.3092e-01,\n",
       "            5.5247e-01, -3.4039e-01, -5.7835e-01, -5.8650e-01, -2.0907e-01,\n",
       "            3.7260e-01,  4.9813e-04, -8.8944e-01, -1.4422e+00,  5.0204e-01,\n",
       "           -3.6208e-01]]], grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Gemma3Actor(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, pad_token_id):\n",
    "        super().__init__()\n",
    "        self.model = Gemma3Model(vocab_size, pad_token_id)\n",
    "        self.lm_head = torch.nn.Linear(1024, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        #input_ids -> [b, lens]\n",
    "        #attention_mask -> [b, lens]\n",
    "        #labels -> [b, lens]\n",
    "\n",
    "        #[b, lens] -> [b, lens, 1024]\n",
    "        logits = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #[b, lens, 1024] -> [b, lens, vocab_size]\n",
    "        logits = self.lm_head(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            labels = torch.nn.functional.pad(labels, (0, 1), value=-100)\n",
    "            labels = labels[..., 1:]\n",
    "\n",
    "            loss = torch.nn.functional.cross_entropy(logits.flatten(end_dim=1),\n",
    "                                                     labels.flatten(),\n",
    "                                                     ignore_index=-100,\n",
    "                                                     reduction='mean')\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "\n",
    "Gemma3Actor(16, 0)(input_ids=torch.randint(0, 16, [2, 15]),\n",
    "                   attention_mask=torch.randint(0, 2, [2, 15]),\n",
    "                   labels=torch.randint(0, 16, [2, 15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b8dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(model_actor, input_ids, pad_token_id, eos_token_id):\n",
    "    max_length = 32\n",
    "    attention_mask = (input_ids != pad_token_id).long()\n",
    "\n",
    "    _, logits = model_actor(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    predict = logits[:, -1].argmax(1, keepdim=True)\n",
    "\n",
    "    input_ids = torch.cat((input_ids, predict), 1)\n",
    "\n",
    "    if input_ids.shape[1] >= max_length:\n",
    "        return input_ids\n",
    "\n",
    "    ends = (input_ids == eos_token_id).sum(1) > 0\n",
    "\n",
    "    if ends.all():\n",
    "        return input_ids\n",
    "\n",
    "    return generate(model_actor, input_ids, pad_token_id, eos_token_id)\n",
    "\n",
    "\n",
    "generate(model_actor=Gemma3Actor(16, 0),\n",
    "         input_ids=torch.randint(0, 16, [2, 15]),\n",
    "         pad_token_id=0,\n",
    "         eos_token_id=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc56abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0837, grad_fn=<MseLossBackward0>),\n",
       " tensor([[-0.6086],\n",
       "         [ 0.9969]], grad_fn=<IndexBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Gemma3Critic(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, pad_token_id, eos_token_id):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = Gemma3Model(vocab_size, pad_token_id)\n",
    "        self.eos_token_id = eos_token_id\n",
    "        self.score = torch.nn.Linear(1024, 1, bias=False)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        #input_ids -> [b, lens]\n",
    "        #attention_mask -> [b, lens]\n",
    "        #labels -> [b, 1]\n",
    "\n",
    "        #[b, lens] -> [b, lens, 1024]\n",
    "        logits = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #[b, lens, 1024] -> [b, lens, 1]\n",
    "        logits = self.score(logits)\n",
    "\n",
    "        ends = []\n",
    "        for i in input_ids:\n",
    "            i = i.tolist()\n",
    "            end = len(i) - 1\n",
    "            if self.eos_token_id in i:\n",
    "                end = i.index(self.eos_token_id)\n",
    "            ends.append(end)\n",
    "\n",
    "        logits = logits[range(input_ids.shape[0]), ends]\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.functional.mse_loss(logits.flatten(),\n",
    "                                                labels.flatten())\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "\n",
    "Gemma3Critic(16, 0, 1)(torch.randint(0, 16, [2, 15]),\n",
    "                       torch.randint(0, 2, [2, 15]), torch.randn(2, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
