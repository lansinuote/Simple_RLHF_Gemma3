{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21004b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tokenizer at 0x7f487d2ac550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "%run 1.tokenizer.ipynb\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bdb9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62500,\n",
       " tensor([[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  2,  0,  7, 13, 13,  5, 14, 11, 10, 11,  9, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  2,  0, 12, 13,  9,  7, 14, 11, 10,  4,  6, 18],\n",
       "         [ 0,  9,  4,  7,  4, 14, 11,  9,  7, 10, 18,  5,  6,  9, 10, 10, 14,  9,\n",
       "           8, 12,  4, 18,  5, 12,  4,  8, 10, 14,  9,  5,  5,  7, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  7,  8,  7, 11, 14,\n",
       "           5, 10,  7,  7, 18,  9,  4, 11,  4, 14,  6, 12,  8, 10, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  9, 13,  4,  9, 14, 11,\n",
       "          13,  4,  7, 18,  5,  7, 12,  4, 12, 14, 13,  6, 10,  4, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0, 11,  6, 13,  7,\n",
       "          14,  9,  5,  5, 18, 11, 12,  4,  8, 14, 12,  7, 10,  5, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0, 12,  9,  9, 12, 14, 11,\n",
       "           7,  5,  4, 18,  5,  9, 12, 10, 12, 14, 13,  8,  4, 12, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  6, 12,  5,  4,\n",
       "          14,  7,  7,  5, 18,  7,  5,  8,  5, 14, 10,  4,  5,  6, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  2,  0, 10,  6,  6,  6, 14,  5,  7,  4,  8, 18],\n",
       "         [ 2,  0, 10,  4,  4,  5, 14,  7,  5,  4,  5, 18, 13,  5,  4,  6, 14,  9,\n",
       "           7, 13, 13, 18,  5,  8,  9,  4,  5, 14, 13,  5,  6,  6, 18],\n",
       "         [ 0, 11,  8,  6,  9, 14,  7,  5,  6,  5, 18,  5,  4,  9,  8, 10, 14, 10,\n",
       "          13,  8,  6, 18,  5, 11,  8, 12, 12, 14,  9, 10, 12,  7, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  2,  0,  5, 11,  6, 13, 14, 11, 10,  4,  7, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  2,  2,  0,  5,  8,  6, 10, 14, 12, 10,  6, 18],\n",
       "         [ 0,  8,  7,  5, 11, 14, 12,  8,  6, 10, 18,  5,  6, 11,  8,  7, 14,  9,\n",
       "           9, 12, 10, 18,  5, 12,  7,  6, 13, 14,  7, 11,  7, 13, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  6, 12, 11, 13, 14, 13,\n",
       "           4,  5,  5, 18,  5,  5, 12, 13,  4, 14,  9, 10, 12,  5, 18],\n",
       "         [ 0,  9, 11,  4,  8, 14,  8,  9, 13,  4, 18,  5,  4,  6, 13,  8, 14,  7,\n",
       "           4,  9, 10, 18,  5,  7,  7,  9,  4, 14,  5,  4,  9,  5, 18]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 2.dataset.ipynb\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    data = [i['text'] for i in data]\n",
    "    return tokenizer(data,\n",
    "                     device=device,\n",
    "                     add_eos_token=False,\n",
    "                     padding_side='left')['input_ids']\n",
    "\n",
    "\n",
    "loader = get_loader(f, negative_label=False, with_answer=False)\n",
    "\n",
    "len(loader), next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a9e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 3.model.ipynb\n",
    "\n",
    "model_actor = torch.load('model/actor', weights_only=False).to(device)\n",
    "model_actor_ref = torch.load('model/actor', weights_only=False).to(device)\n",
    "\n",
    "model_critic = torch.load('model/critic', weights_only=False).to(device)\n",
    "model_critic_ref = torch.load('model/critic', weights_only=False).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(model_actor.parameters()) +\n",
    "                              list(model_critic.parameters()),\n",
    "                              lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddef38a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_value(critic, question, answer, shift=True):\n",
    "    input_ids = torch.cat((question, answer), 1)\n",
    "    attention_mask = input_ids != tokenizer.pad_token_id\n",
    "    input_ids = torch.masked_fill(input_ids, ~attention_mask, 0)\n",
    "\n",
    "    #[b, lens, 768]\n",
    "    last_hidden_state = critic.model(input_ids=input_ids,\n",
    "                                     attention_mask=attention_mask)\n",
    "\n",
    "    #[b, lens]\n",
    "    value = critic.score(last_hidden_state)\n",
    "\n",
    "    if shift:\n",
    "        value = value[:, question.shape[1] - 1:-1].squeeze(-1)\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "get_value(model_critic,\n",
    "          torch.randint(0, 10, [2, 5]).to(device),\n",
    "          torch.randint(0, 10, [2, 15]).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daab666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_logprob(actor, question, answer):\n",
    "    input_ids = torch.cat((question, answer), 1)\n",
    "    attention_mask = input_ids != tokenizer.pad_token_id\n",
    "    input_ids = torch.masked_fill(input_ids, ~attention_mask, 0)\n",
    "\n",
    "    _, logits = actor(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    logits = logits[:, question.shape[1] - 1:-1] / 0.7\n",
    "\n",
    "    logprob = logits.log_softmax(dim=-1)\n",
    "    logprob = logprob.gather(2, answer.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    return logprob\n",
    "\n",
    "\n",
    "get_logprob(model_actor,\n",
    "            torch.randint(0, 10, [2, 5]).to(device),\n",
    "            torch.randint(0, 10, [2, 15]).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f41b6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_advantage(value, reward_kl):\n",
    "    advantage = []\n",
    "    last = 0\n",
    "    for i in reversed(range(value.shape[1])):\n",
    "        value_next = 0.0\n",
    "        if i < value.shape[1] - 1:\n",
    "            value_next = value[:, i + 1]\n",
    "\n",
    "        delta = reward_kl[:, i] + value_next - value[:, i]\n",
    "\n",
    "        last = delta + 0.95 * last\n",
    "\n",
    "        advantage.append(last)\n",
    "\n",
    "    return torch.stack(advantage[::-1], axis=1)\n",
    "\n",
    "\n",
    "get_advantage(torch.randn(4, 25), torch.randn(4, 25)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff581cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pt2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0, 12, 13,\n",
       "           8, 14,  8,  4, 18, 13,  7,  8, 14,  9,  4,  6,  7, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  0,  5, 12,  6,  5, 14, 11,  4, 12,  8, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  0,  7, 12, 11, 12, 14, 10,  9,  4,  8, 18],\n",
       "         [ 2,  2,  0,  6,  7,  4,  4, 14, 10,  7,  8, 18,  6, 13,  7,  8, 14,  5,\n",
       "           4, 12, 13, 18,  8,  4,  6,  7, 14,  8, 11,  5,  5, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  6,  9, 12,  7, 14, 10,\n",
       "           5, 12,  8, 18, 12, 11, 10, 11, 14,  8,  4,  6,  5, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  5,  5, 10,  4, 14,  5,\n",
       "           4,  7,  9, 18,  6,  5, 13,  9, 14, 11,  5, 12, 10, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  0,  8, 10, 13, 12, 14, 13,  7, 12,  5, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  9,  4,  4,  6, 14, 11, 10,\n",
       "           5,  9, 18,  5,  6, 10,  5, 11, 14, 10,  6,  7,  7, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0, 10,  8, 13,  7, 14, 12,\n",
       "          13,  9, 12, 18,  5,  9,  8,  9,  5, 14, 12,  4,  6, 18],\n",
       "         [ 0, 13, 10,  4,  9, 14,  9, 12,  7,  4, 18,  5,  9,  8,  7,  9, 14, 12,\n",
       "          11, 12, 18,  5, 10,  7,  5,  7, 14,  7, 11, 10,  8, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  8,  5,  5,  6, 14,  8,\n",
       "           9,  8,  8, 18, 12, 10,  9, 10, 14,  7, 11,  4,  7, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  2,  2,  0, 12,  9, 12, 14,  8,  7, 13, 18],\n",
       "         [ 2,  2,  0, 12,  9,  7, 14,  5, 11, 13,  6, 18,  6, 10,  8,  9, 14, 10,\n",
       "          11, 10,  9, 18, 13,  8,  5,  4, 14, 12, 12,  8, 10, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  8,  7, 12,  4, 14,\n",
       "           6,  8,  5, 18,  8, 10,  6,  5, 14,  8,  9,  8,  9, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  9,  8, 10,  8, 14,  5,\n",
       "          13,  6,  6, 18, 11,  7, 12, 10, 14, 13, 11,  8, 10, 18],\n",
       "         [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  8,  4,  6, 13, 14, 10, 13,\n",
       "           8, 12, 18,  5,  4, 13, 11, 11, 14,  7,  5,  7, 12, 18]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 9, 13,  9, 11, 14,  8, 10,  4, 18, 10,  8,  5, 11,  1,  3, 12, 18, 11,\n",
       "           7,  5, 10,  1,  0,  9, 10,  7],\n",
       "         [12, 13,  4,  9, 14,  8,  9,  6,  5, 18,  5,  7,  8,  6, 10, 14,  8,  5,\n",
       "           5, 18,  5,  7, 12,  7, 11,  1],\n",
       "         [ 5,  4,  7, 12,  6, 14,  8, 11,  5, 13, 18,  5,  9,  5,  4,  5,  1,  3,\n",
       "          12, 11, 12, 12, 18,  5, 11,  4],\n",
       "         [12, 11,  7,  8,  1,  3, 12, 18,  5, 12, 13,  7,  1,  0,  5,  8,  6, 12,\n",
       "          12, 14,  8,  9,  5, 13, 18,  9],\n",
       "         [ 5,  6, 11, 12, 12, 14,  8, 11,  5,  5, 18,  5, 11,  8, 13, 13,  1,  3,\n",
       "          12, 11,  5, 10, 12,  8, 12, 11],\n",
       "         [13,  7, 12,  5,  1,  3, 12, 18,  6, 13,  8,  7,  1,  0,  6,  6, 10, 12,\n",
       "          12, 14, 11,  5,  5, 13, 18, 13],\n",
       "         [ 5,  8,  4, 11, 13, 14,  8, 11,  5,  5, 18,  5, 12, 11, 13,  4,  1,  3,\n",
       "          12, 18,  5, 12, 13, 11, 12,  1],\n",
       "         [ 5, 12, 12,  9,  4,  1,  3, 12, 18,  5,  7, 13,  8, 12,  1,  3, 12,  9,\n",
       "          18,  5, 12,  4,  9,  8,  1,  3],\n",
       "         [ 5, 10,  6,  9,  7, 14,  8, 11,  5, 18,  5, 10, 11,  6,  8,  1,  3, 12,\n",
       "          11, 10, 12, 12,  8,  9,  4,  5],\n",
       "         [ 6,  4,  4, 11, 11,  1,  3, 12, 18,  6, 12,  4, 11,  1,  0,  8, 10, 10,\n",
       "          12, 14,  8, 10,  8, 12, 18, 13],\n",
       "         [ 5,  6,  7,  9, 13,  1,  3, 12, 18,  5,  6,  8,  8,  4,  1,  3, 12, 12,\n",
       "          18,  5, 12, 12, 13,  9,  1,  3],\n",
       "         [ 5,  6, 13, 11, 14,  8, 11,  5,  5, 18, 10,  4,  4, 12, 14,  8, 11,  5,\n",
       "           5, 18,  5,  4, 11,  5, 13,  1],\n",
       "         [ 5, 12,  6,  9, 10,  1,  3, 12, 18,  5,  8, 13,  8, 13,  1,  3, 12, 11,\n",
       "          11, 10, 12,  9, 10,  6, 11, 10],\n",
       "         [13,  5, 10, 10, 14,  8, 11,  5, 18, 13, 10,  7, 11,  1,  0, 13, 10,  8,\n",
       "          12, 14,  8, 10,  4,  4, 18,  5],\n",
       "         [ 5, 11,  5,  7,  6, 14,  8, 10,  4, 18,  5, 11,  9, 13,  6,  1,  3, 12,\n",
       "          18,  5, 12,  8, 11, 13,  1,  3],\n",
       "         [ 5,  8,  5,  5,  9,  1,  3, 12,  7, 13, 13,  7,  7, 13,  5,  9,  5, 10,\n",
       "          12, 18,  5,  4,  5,  5,  4,  1]], device='cuda:0'),\n",
       " [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26],\n",
       " tensor([[-2.6226e-06, -2.8610e-06, -3.5763e-07, -5.9605e-07, -6.8343e-01,\n",
       "          -2.1303e+00, -2.2758e+00, -2.2033e+00, -2.1499e+00, -5.9605e-07,\n",
       "          -8.9407e-06, -1.0371e-05, -1.0729e-06, -1.3113e-06, -1.4287e+00,\n",
       "          -1.8072e+00, -1.8958e-01, -2.9546e-01, -1.4501e-01, -1.1629e-01,\n",
       "          -6.8938e-01, -6.7949e-06, -1.5094e+00, -1.9183e+00, -2.0766e+00,\n",
       "          -2.2273e+00],\n",
       "         [-1.1921e-07, -2.2397e-04,  0.0000e+00, -3.5763e-07, -2.9674e-01,\n",
       "          -2.1531e+00, -2.2616e+00, -2.2398e+00, -2.2992e+00,  0.0000e+00,\n",
       "           0.0000e+00, -1.0729e-06, -1.2994e-05, -3.5763e-07, -2.3842e-07,\n",
       "          -6.7295e-01, -2.1550e+00, -2.2575e+00, -2.1927e+00, -2.3141e+00,\n",
       "          -3.5763e-07, -1.5497e-06, -1.0729e-05, -1.7881e-06, -3.5763e-07,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -2.3842e-07, -1.4305e-06, -2.3842e-07,\n",
       "          -3.1719e-01, -2.1608e+00, -2.2566e+00, -2.1859e+00, -2.3238e+00,\n",
       "           0.0000e+00, -1.1921e-07, -1.1921e-07, -4.7684e-07,  0.0000e+00,\n",
       "          -2.3842e-07, -6.5093e-01, -1.4280e+00, -1.9012e+00, -1.6059e+00,\n",
       "          -2.1761e+00, -8.5338e-01, -3.1086e-01, -2.8610e-06, -4.8662e-02,\n",
       "          -5.9274e-03],\n",
       "         [-4.7684e-07, -4.7684e-07, -3.5763e-07, -1.1921e-06, -1.1921e-07,\n",
       "          -1.4278e+00, -1.8303e+00, -7.0025e-02, -5.9245e-05, -2.6226e-05,\n",
       "          -4.1723e-06, -6.5001e-01, -1.3041e-04, -1.4888e+00, -1.8876e+00,\n",
       "          -1.8877e+00, -2.2351e+00, -2.2082e+00, -1.7843e+00, -6.4940e-01,\n",
       "          -2.1557e+00, -2.2328e+00, -2.2553e+00, -2.3017e+00,  0.0000e+00,\n",
       "          -3.2098e-01],\n",
       "         [ 0.0000e+00, -4.7684e-07, -1.1921e-07, -1.1921e-07, -2.3842e-07,\n",
       "          -6.8188e-01, -2.1597e+00, -2.2714e+00, -2.1633e+00, -2.3158e+00,\n",
       "           0.0000e+00, -1.1921e-07, -2.7418e-06, -1.1921e-06, -1.1921e-07,\n",
       "           0.0000e+00, -3.5763e-07, -1.3834e+00, -1.7232e+00, -1.5985e+00,\n",
       "          -2.1122e+00, -2.0021e+00, -1.9369e+00, -2.9444e-01, -2.5889e-01,\n",
       "          -3.2908e-04],\n",
       "         [-1.1921e-07, -1.4305e-06, -2.3842e-05, -1.1921e-07, -6.8321e-01,\n",
       "          -1.4089e+00, -1.7073e+00, -4.2192e-01, -7.0333e-06, -1.4424e-05,\n",
       "          -6.1720e-03, -3.9116e-02, -1.3672e-04, -1.3765e+00, -1.8542e+00,\n",
       "          -2.1187e+00, -2.1992e+00, -2.1734e+00, -1.1772e+00, -4.8483e-01,\n",
       "          -2.1511e+00, -2.1918e+00, -2.1957e+00, -2.3100e+00,  0.0000e+00,\n",
       "          -1.1921e-07],\n",
       "         [-1.1921e-07, -1.6093e-05,  0.0000e+00, -1.1921e-07, -2.3842e-07,\n",
       "          -3.3150e-01, -2.1571e+00, -2.2559e+00, -2.1508e+00, -2.2935e+00,\n",
       "           0.0000e+00, -5.9605e-07, -7.1526e-07, -1.7881e-06, -1.9073e-06,\n",
       "          -1.1921e-07, -6.5073e-01, -1.3647e+00, -1.6310e+00, -7.6636e-01,\n",
       "          -3.5763e-07, -1.3113e-05, -4.0297e-04, -9.4835e-01, -1.9669e-05,\n",
       "          -7.1526e-07],\n",
       "         [-3.5763e-07, -2.3842e-07, -5.9605e-07, -4.7684e-07, -1.1921e-07,\n",
       "          -6.5441e-01, -1.3757e+00, -1.8796e+00, -1.2435e-01, -2.3842e-07,\n",
       "          -1.0850e-02, -1.3947e-05, -1.9074e-02, -6.3958e-01, -4.7684e-07,\n",
       "          -1.4387e+00, -1.8438e+00, -1.2854e+00, -4.5055e-02, -3.5763e-07,\n",
       "          -9.2289e-02, -1.0252e-05, -4.4107e-06, -5.5600e-02, -1.4663e-05,\n",
       "          -1.4855e+00],\n",
       "         [-1.1921e-07, -1.7881e-06, -4.8876e-06, -1.1921e-06, -7.1526e-07,\n",
       "          -6.9152e-01, -2.1555e+00, -2.2760e+00, -2.1591e+00, -2.3138e+00,\n",
       "          -8.3446e-07, -2.8610e-06, -1.8239e-05, -5.9605e-07, -8.3446e-07,\n",
       "           0.0000e+00, -1.3925e+00, -1.8574e+00, -1.9514e+00, -2.1703e+00,\n",
       "          -2.1945e+00, -1.8258e+00, -7.6387e-01, -3.8488e-01, -1.2251e-02,\n",
       "          -1.1466e-01],\n",
       "         [-6.1033e-05,  0.0000e+00,  0.0000e+00, -3.5763e-07, -3.5763e-07,\n",
       "           0.0000e+00, -1.4052e+00, -1.8695e+00, -9.0443e-02, -1.3113e-06,\n",
       "          -3.8514e-02, -4.3562e-02, -2.9352e-02, -4.3936e-01, -1.4783e+00,\n",
       "          -1.9336e+00, -2.1472e+00, -2.2135e+00, -2.1383e+00, -9.3035e-02,\n",
       "          -2.1549e+00, -2.2053e+00, -2.2207e+00, -2.3249e+00,  0.0000e+00,\n",
       "          -1.0610e-05],\n",
       "         [ 0.0000e+00, -1.1921e-07, -2.3842e-07, -1.1921e-07, -1.1921e-07,\n",
       "          -6.9211e-01, -1.3683e+00, -1.8351e+00, -2.3036e-03,  0.0000e+00,\n",
       "          -6.3626e-04, -1.2278e-05, -1.2226e-02, -3.1337e-01, -1.5259e-05,\n",
       "          -1.3987e+00, -1.8111e+00, -6.4806e-01, -1.2870e-02, -1.1921e-07,\n",
       "          -1.3947e-05, -2.4586e-01, -1.3113e-05, -1.3138e-03, -4.7684e-07,\n",
       "          -1.4687e+00],\n",
       "         [-1.3113e-06, -5.9604e-06, -5.9605e-07, -8.3446e-07, -3.5080e-01,\n",
       "          -2.1384e+00, -2.2588e+00, -2.1556e+00, -2.3051e+00,  0.0000e+00,\n",
       "          -5.5669e-05,  0.0000e+00,  0.0000e+00, -8.3446e-07, -6.5535e-01,\n",
       "          -2.1375e+00, -2.2383e+00, -2.1624e+00, -2.2969e+00,  0.0000e+00,\n",
       "          -1.1921e-07,  0.0000e+00, -4.7684e-07, -1.1921e-07, -1.1921e-07,\n",
       "          -4.7684e-07],\n",
       "         [-1.1921e-07, -3.5763e-07, -2.3842e-07,  0.0000e+00, -1.1921e-07,\n",
       "           0.0000e+00, -1.3963e+00, -1.8911e+00, -5.1437e-04, -2.1457e-05,\n",
       "          -3.1657e-04, -4.4464e-05, -1.0636e+00, -1.0555e-01, -8.3446e-07,\n",
       "          -1.3841e+00, -1.8077e+00, -3.8778e-01, -1.3806e+00, -1.9916e+00,\n",
       "          -1.7066e+00, -9.9362e-01, -8.5490e-03, -2.1656e-01, -3.1968e-03,\n",
       "          -4.7565e-04],\n",
       "         [-7.1526e-07, -7.1526e-07, -4.7684e-07, -4.7684e-07, -6.2893e-01,\n",
       "          -2.1478e+00, -2.2600e+00, -2.1771e+00, -2.2748e+00, -2.3842e-07,\n",
       "          -5.7220e-06, -2.1458e-06, -5.9605e-07, -1.1921e-07, -1.4268e+00,\n",
       "          -1.9151e+00, -2.1013e+00, -2.1943e+00, -2.2873e+00, -1.8213e-02,\n",
       "          -2.1301e+00, -2.2177e+00, -2.1939e+00, -2.3146e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-2.3842e-07, -3.4093e-05, -2.3842e-07, -8.3446e-07, -1.1921e-07,\n",
       "          -6.8572e-01, -2.1579e+00, -2.2624e+00, -2.2284e+00, -2.2960e+00,\n",
       "          -1.1921e-07, -2.8610e-06, -2.3842e-06, -2.9802e-06, -7.1526e-07,\n",
       "           0.0000e+00, -1.3995e+00, -1.8188e+00, -5.5063e-01, -2.2683e-04,\n",
       "          -3.4802e-01, -2.4918e-03, -6.9040e-01, -1.7427e-04, -1.0729e-06,\n",
       "          -1.4017e+00],\n",
       "         [-1.1921e-07, -3.5763e-07, -4.7684e-07, -1.1921e-07, -1.1921e-07,\n",
       "          -6.8231e-01, -1.4482e+00, -1.8783e+00, -1.8297e+00, -2.2074e+00,\n",
       "          -2.1801e+00, -2.1463e+00, -1.7263e+00, -4.8888e-04, -2.1554e-03,\n",
       "          -7.2285e-03, -3.2997e-02, -1.4740e+00, -2.0409e+00, -4.5230e-04,\n",
       "          -2.2259e-01, -3.5763e-07, -9.7978e-04, -5.1993e-02, -1.1877e-03,\n",
       "          -1.4305e-06]], device='cuda:0'),\n",
       " tensor([[ 1.7774e-01, -3.7302e-01,  1.8744e+00, -9.5165e-01,  7.4437e-01,\n",
       "          -9.3517e-02,  1.8493e+00, -2.4743e-01,  8.8785e-01,  3.7632e-01,\n",
       "          -2.0307e-01,  1.4610e+00,  7.6206e-01,  8.1844e-01,  8.3547e-01,\n",
       "           3.4807e-01,  8.6190e-01,  7.3539e-01,  9.7996e-01,  1.4739e+00,\n",
       "           7.6583e-01, -4.8005e-01,  5.8612e-01,  6.1681e-01,  5.1561e-02,\n",
       "          -1.1922e-01],\n",
       "         [ 5.1998e-01,  1.1127e+00,  1.4977e+00,  1.0996e+00,  1.7879e-01,\n",
       "          -5.0954e-01,  1.4877e+00, -8.5425e-03,  1.5235e+00,  9.4790e-01,\n",
       "           6.9964e-01,  1.1598e+00,  1.3589e+00,  1.2137e+00,  9.5646e-01,\n",
       "          -9.9316e-01,  3.8798e-01,  1.2658e+00,  1.0761e+00,  1.0932e+00,\n",
       "           7.0577e-01,  9.2682e-01,  1.3078e+00,  9.0004e-01,  1.1761e+00,\n",
       "           1.0584e+00],\n",
       "         [ 6.0132e-01,  9.7146e-01,  9.4091e-01,  1.6270e+00,  8.4997e-01,\n",
       "           1.1656e+00, -6.8544e-04,  1.4268e+00,  9.0360e-01,  1.2095e+00,\n",
       "           1.4260e+00,  5.5904e-01,  1.3414e+00, -3.3068e-01,  1.2281e-01,\n",
       "           1.1081e+00,  6.5460e-01,  9.5102e-01,  6.4906e-01,  6.1051e-01,\n",
       "           6.8929e-01,  9.0629e-01,  1.0480e+00,  2.7973e-01,  1.0833e+00,\n",
       "           7.9207e-01],\n",
       "         [ 2.2397e-01,  8.7870e-01,  9.0181e-01,  1.2298e+00,  1.0710e+00,\n",
       "           9.3338e-01,  3.9997e-01,  7.7076e-01,  1.7543e-01,  1.0137e+00,\n",
       "           1.2898e+00,  1.5938e+00,  1.6293e+00,  8.8795e-02,  7.0285e-01,\n",
       "           6.9995e-01,  1.5741e+00,  1.0652e+00,  8.4715e-01,  1.0104e+00,\n",
       "          -8.5392e-02,  1.5124e+00, -2.9694e-01,  1.2134e+00,  1.7793e+00,\n",
       "           4.4028e-01],\n",
       "         [ 4.5204e-01,  9.5542e-01,  9.2529e-01,  9.0207e-01,  2.9587e-01,\n",
       "           1.0445e-01, -9.1793e-02,  1.2054e+00,  7.2546e-01,  1.0687e+00,\n",
       "           1.0715e+00,  4.4681e-01,  8.7257e-01,  9.3875e-01,  1.1823e+00,\n",
       "           1.4257e+00,  1.2401e+00,  9.3545e-01,  6.4487e-01,  9.8077e-01,\n",
       "           7.9334e-01,  5.9523e-01, -4.1975e-01,  6.9911e-01,  1.4308e+00,\n",
       "           1.0718e+00],\n",
       "         [ 2.8819e-01,  1.5293e+00,  1.1302e+00,  9.8881e-01,  5.9517e-01,\n",
       "           9.4149e-01,  6.4711e-03,  8.1679e-01,  4.8971e-01,  1.3158e+00,\n",
       "           1.7318e+00,  1.4305e+00,  1.5854e+00,  9.8976e-02,  5.3207e-01,\n",
       "           9.8586e-01,  1.2736e+00, -2.9295e-01,  8.9652e-01,  9.6295e-01,\n",
       "           1.1499e-01,  8.5028e-01,  9.5690e-01,  1.4177e+00,  1.8404e+00,\n",
       "           3.7334e-01],\n",
       "         [ 6.3975e-01,  1.0981e+00,  1.2764e+00,  1.0232e+00,  8.4812e-01,\n",
       "           1.1502e+00, -7.4956e-01,  1.4494e+00,  9.7122e-01,  6.9036e-01,\n",
       "           5.1996e-01,  7.9368e-01,  1.1771e+00,  1.2352e+00,  8.7800e-01,\n",
       "           1.5618e+00,  1.0414e+00,  9.3091e-01,  4.6484e-01,  6.4980e-01,\n",
       "           6.0832e-02,  6.4682e-01,  1.0513e+00,  1.8567e+00,  7.9799e-01,\n",
       "           1.3262e+00],\n",
       "         [-2.9193e-01,  7.6736e-01,  1.1492e+00,  1.2056e+00, -4.1825e-01,\n",
       "           1.2642e+00,  9.1644e-01,  9.8346e-01,  7.6536e-01,  5.7603e-01,\n",
       "           8.8182e-01,  1.3648e+00,  1.5859e+00,  1.4263e+00,  8.4317e-01,\n",
       "           7.1144e-01,  6.2422e-01,  9.2992e-01,  3.4895e-01,  1.9558e-02,\n",
       "           6.0931e-01,  1.0301e+00,  8.5491e-01,  2.3969e-01,  1.5254e+00,\n",
       "           4.6815e-01],\n",
       "         [ 4.2870e-01,  8.7867e-01, -6.2988e-01,  1.2247e+00, -4.7128e-01,\n",
       "           8.6420e-01, -3.4743e-01,  1.2811e+00,  6.5572e-01,  1.1805e+00,\n",
       "           4.7869e-01,  1.1948e+00, -2.3162e-01,  7.6628e-01,  1.1678e+00,\n",
       "           1.1974e+00,  9.4714e-01,  5.8386e-01,  9.1288e-01,  6.1182e-01,\n",
       "          -3.5174e-01,  1.3480e+00,  9.8361e-01,  1.2949e+00, -2.4276e-02,\n",
       "           1.0211e+00],\n",
       "         [ 5.9036e-01,  1.3230e+00,  9.4548e-01,  9.4982e-01,  5.5878e-01,\n",
       "           5.9259e-01,  9.3117e-01,  5.9356e-01,  9.9941e-01,  2.2872e-01,\n",
       "           8.0688e-01,  1.1316e+00,  1.3750e+00,  8.1046e-01,  6.4544e-01,\n",
       "           4.2480e-01,  1.3138e+00, -3.0037e-01, -4.8756e-01,  9.0369e-01,\n",
       "           8.8482e-02,  1.5773e+00, -1.4145e-02,  1.3086e+00,  9.3677e-01,\n",
       "           1.5648e-01],\n",
       "         [ 2.6799e-01,  7.5438e-01,  1.0799e+00,  1.1540e+00, -8.7953e-02,\n",
       "           1.0038e+00,  9.3884e-01,  6.6110e-01,  1.0839e+00,  3.1082e-01,\n",
       "           9.3383e-01,  1.1384e+00,  1.0998e+00,  9.2890e-01,  8.3702e-01,\n",
       "           1.6117e-01,  6.5023e-01,  8.5702e-01,  7.7713e-01,  6.8355e-01,\n",
       "           8.6487e-01,  8.3135e-01,  6.9773e-01,  1.5941e+00,  9.5058e-02,\n",
       "           2.5357e-02],\n",
       "         [ 1.7551e-01,  1.2856e+00,  1.6875e+00,  1.4838e+00,  1.1655e+00,\n",
       "          -4.4708e-01,  1.4241e+00,  9.6505e-01,  7.6691e-01,  8.9579e-01,\n",
       "           5.5748e-01, -3.0942e-01,  8.8826e-01,  7.6417e-01,  4.3649e-01,\n",
       "          -1.6030e-01,  1.1282e+00,  8.3609e-01,  1.1571e+00,  1.5228e+00,\n",
       "           5.6894e-01,  1.4051e+00,  8.8698e-01,  1.2242e+00,  3.4467e-01,\n",
       "           1.3805e+00],\n",
       "         [ 1.0674e+00,  1.1142e+00,  9.0150e-01,  1.2940e+00,  1.1018e-01,\n",
       "          -2.9579e-01,  9.2416e-01,  9.5331e-02,  6.2596e-01,  3.2604e-01,\n",
       "           8.1080e-01,  1.2547e+00,  1.5661e+00,  1.1976e+00,  1.4842e+00,\n",
       "           1.1427e-01,  4.7978e-01,  1.0479e+00,  1.0102e+00,  9.0589e-01,\n",
       "          -4.1259e-01,  6.4053e-01, -2.1372e-01, -4.3572e-01,  1.2592e+00,\n",
       "           1.0117e+00],\n",
       "         [ 8.4237e-01,  2.1836e+00,  9.8061e-01, -4.9970e-02, -3.9935e-01,\n",
       "           6.4470e-03,  1.5044e+00,  9.3891e-01,  9.6362e-01,  5.8665e-01,\n",
       "           1.9536e+00, -5.7942e-01,  1.1615e+00,  8.3104e-01,  9.2304e-01,\n",
       "           6.8291e-01,  1.2881e+00, -5.1052e-01,  1.4693e+00,  1.0113e+00,\n",
       "          -1.0523e-01,  1.2301e+00, -2.3330e-01,  1.0161e+00,  1.1782e+00,\n",
       "           4.5180e-01],\n",
       "         [ 1.1417e+00,  8.5398e-01,  8.3031e-01,  6.5764e-01,  1.3772e+00,\n",
       "           9.0224e-01, -3.0244e-01,  1.2700e+00, -4.4632e-01,  1.1449e+00,\n",
       "           4.6602e-01,  8.7809e-01,  7.9491e-01,  3.1072e-01,  1.4268e+00,\n",
       "           1.1805e+00,  9.1742e-01,  4.6823e-01,  1.2017e+00,  4.7226e-01,\n",
       "           7.7490e-01,  1.3422e+00,  1.4635e+00,  8.5636e-01,  1.4731e+00,\n",
       "           3.9722e-01],\n",
       "         [-3.2915e-01,  8.3456e-01,  1.1144e+00,  5.0042e-01,  7.4690e-01,\n",
       "          -8.9251e-02,  9.2695e-01,  9.2983e-01,  9.4799e-01,  1.3171e+00,\n",
       "           1.7657e+00,  2.1055e+00,  1.7054e+00,  1.6933e+00,  1.4251e+00,\n",
       "           7.5453e-01,  2.8426e-01,  6.4123e-01, -4.6776e-01,  8.3590e-01,\n",
       "           6.7504e-01,  1.0513e+00,  1.0296e+00,  7.7228e-01,  1.0337e+00,\n",
       "           8.3136e-01]], device='cuda:0'),\n",
       " tensor([[ 8.0823e-01,  1.7374e+00, -1.7686e+00,  2.6712e+00,  9.8013e-02,\n",
       "           1.4500e+00, -1.5830e+00,  1.6978e+00, -2.8089e-02,  7.9423e-01,\n",
       "           1.7686e+00, -8.0098e-01,  2.8106e-01,  2.0958e-01,  1.9738e-01,\n",
       "           9.9291e-01,  2.2585e-01,  4.4454e-01,  8.0102e-02, -7.0322e-01,\n",
       "           3.9859e-01,  2.4202e+00,  8.4309e-01,  8.4236e-01,  1.7966e+00,\n",
       "           2.1689e+00],\n",
       "         [ 4.5574e-01, -4.6603e-01, -1.1034e+00, -5.1954e-01,  9.3285e-01,\n",
       "           2.0891e+00, -9.9754e-01,  1.3518e+00, -1.0280e+00, -1.5566e-01,\n",
       "           2.3807e-01, -4.8276e-01, -8.2318e-01, -6.2964e-01, -2.4652e-01,\n",
       "           2.8688e+00,  8.1064e-01, -5.4934e-01, -2.7022e-01, -3.0772e-01,\n",
       "           3.0105e-01, -3.3259e-02, -6.4139e-01, -1.7692e-02, -4.5688e-01,\n",
       "          -2.8832e-01],\n",
       "         [ 3.6828e-01, -2.0140e-01, -1.5896e-01, -1.2626e+00, -7.9893e-02,\n",
       "          -5.8581e-01,  1.2564e+00, -9.6087e-01, -1.6901e-01, -6.6406e-01,\n",
       "          -1.0419e+00,  2.9671e-01, -9.3733e-01,  1.6969e+00,  1.0636e+00,\n",
       "          -4.5529e-01,  2.5158e-01, -2.0611e-01,  2.7101e-01,  3.5113e-01,\n",
       "           2.4745e-01, -8.3198e-02, -3.1063e-01,  9.0830e-01, -3.2747e-01,\n",
       "           1.2600e-01],\n",
       "         [ 5.5619e-01, -4.5967e-01, -5.1681e-01, -1.0655e+00, -8.6311e-01,\n",
       "          -6.8386e-01,  1.3900e-01, -4.4379e-01,  4.9094e-01, -8.2243e-01,\n",
       "          -1.3042e+00, -1.8558e+00, -2.0064e+00,  3.6081e-01, -6.0014e-01,\n",
       "          -6.2300e-01, -2.0525e+00, -1.3410e+00, -1.0580e+00, -1.3712e+00,\n",
       "           3.1665e-01, -2.2230e+00,  5.6349e-01, -1.8231e+00, -2.8218e+00,\n",
       "          -8.2049e-01],\n",
       "         [ 4.7362e-01, -3.0403e-01, -2.6767e-01, -2.4047e-01,  7.2239e-01,\n",
       "           1.0712e+00,  1.4462e+00, -5.5245e-01,  1.9173e-01, -3.4406e-01,\n",
       "          -3.6258e-01,  6.2340e-01, -2.1990e-02, -1.2511e-01, -5.1787e-01,\n",
       "          -9.3109e-01, -6.7862e-01, -2.2208e-01,  2.3597e-01, -2.8581e-01,\n",
       "           3.5783e-03,  3.2532e-01,  1.9730e+00,  2.8798e-01, -8.6537e-01,\n",
       "          -3.3152e-01],\n",
       "         [ 1.1694e+00, -7.5380e-01, -1.4980e-01,  7.2937e-02,  7.1166e-01,\n",
       "           1.9822e-01,  1.7111e+00,  5.0671e-01,  1.0616e+00, -2.0218e-01,\n",
       "          -8.7542e-01, -4.3469e-01, -7.0166e-01,  1.6475e+00,  1.0442e+00,\n",
       "           3.7608e-01, -6.1115e-02,  2.4501e+00,  6.7701e-01,  6.1028e-01,\n",
       "           2.0053e+00,  9.3665e-01,  8.1918e-01,  1.2794e-01, -5.3860e-01,\n",
       "           1.7881e+00],\n",
       "         [ 2.4479e-01, -4.7270e-01, -7.7931e-01, -4.1045e-01, -1.4742e-01,\n",
       "          -6.3524e-01,  2.3798e+00, -1.0147e+00, -2.9771e-01,  1.4077e-01,\n",
       "           4.2533e-01,  1.3159e-02, -5.9645e-01, -7.1694e-01, -1.7816e-01,\n",
       "          -1.2792e+00, -5.0850e-01, -3.5418e-01,  3.7813e-01,  1.0571e-01,\n",
       "           1.0592e+00,  1.7996e-01, -4.5472e-01, -1.7652e+00, -1.5743e-01,\n",
       "          -1.0081e+00],\n",
       "         [ 1.5349e+00, -7.7714e-02, -6.8957e-01, -8.1219e-01,  1.7513e+00,\n",
       "          -8.4853e-01, -3.3182e-01, -4.5262e-01, -1.2286e-01,  1.7816e-01,\n",
       "          -2.9842e-01, -1.0840e+00, -1.4912e+00, -1.3099e+00, -4.4035e-01,\n",
       "          -2.4835e-01, -1.1757e-01, -6.0957e-01,  2.9343e-01,  8.4081e-01,\n",
       "          -5.5929e-02, -7.2907e-01, -4.8266e-01,  4.8191e-01, -1.5490e+00,\n",
       "           6.7797e-02],\n",
       "         [ 2.9084e-01, -4.1085e-01,  1.9891e+00, -8.7410e-01,  1.8017e+00,\n",
       "          -2.3947e-01,  1.6936e+00, -8.2280e-01,  1.4009e-01, -6.8944e-01,\n",
       "           4.0303e-01, -7.1922e-01,  1.5328e+00,  1.8446e-02, -6.1995e-01,\n",
       "          -6.9591e-01, -3.2743e-01,  2.4157e-01, -2.6889e-01,  2.0348e-01,\n",
       "           1.7624e+00, -8.6462e-01, -3.2211e-01, -8.3379e-01,  1.2403e+00,\n",
       "          -3.6546e-01],\n",
       "         [ 6.9920e-01, -4.3393e-01,  1.5224e-01,  1.5739e-01,  7.9638e-01,\n",
       "           7.8821e-01,  2.9119e-01,  8.5161e-01,  2.5015e-01,  1.5024e+00,\n",
       "           6.5908e-01,  1.7751e-01, -1.9910e-01,  6.9913e-01,  1.0044e+00,\n",
       "           1.4150e+00,  6.8819e-02,  2.6633e+00,  3.1075e+00,  1.0457e+00,\n",
       "           2.4112e+00,  1.5636e-01,  2.7189e+00,  7.4641e-01,  1.3856e+00,\n",
       "           2.7130e+00],\n",
       "         [ 7.2810e-01, -8.9412e-03, -5.2700e-01, -6.6931e-01,  1.2897e+00,\n",
       "          -3.8792e-01, -3.0012e-01,  1.3325e-01, -5.3314e-01,  6.8169e-01,\n",
       "          -2.7672e-01, -6.1510e-01, -5.8155e-01, -3.3413e-01, -2.0040e-01,\n",
       "           8.7618e-01,  1.4265e-01, -1.7715e-01, -5.4367e-02,  9.6811e-02,\n",
       "          -1.8457e-01, -1.3649e-01,  7.4527e-02, -1.3539e+00,  9.8113e-01,\n",
       "           1.1485e+00],\n",
       "         [ 1.0369e+00, -6.8340e-01, -1.3593e+00, -1.1004e+00, -6.4407e-01,\n",
       "           1.9102e+00, -9.8374e-01, -2.9579e-01,  1.0241e-02, -1.9167e-01,\n",
       "           3.4447e-01,  1.7559e+00, -6.6897e-02,  1.3251e-01,  6.6866e-01,\n",
       "           1.6643e+00, -3.0878e-01,  1.4708e-01, -3.5549e-01, -9.5613e-01,\n",
       "           5.2613e-01, -7.8201e-01,  1.1166e-02, -5.2454e-01,  8.6136e-01,\n",
       "          -7.4917e-01],\n",
       "         [-9.7593e-01, -1.0982e+00, -8.1102e-01, -1.4786e+00,  3.4471e-01,\n",
       "           1.0175e+00, -8.7984e-01,  4.0613e-01, -4.1874e-01,  4.3909e-02,\n",
       "          -7.2652e-01, -1.4720e+00, -2.0445e+00, -1.5575e+00, -2.0946e+00,\n",
       "          -5.4710e-03, -5.8740e-01, -1.5247e+00, -1.5405e+00, -1.4502e+00,\n",
       "           5.9036e-01, -1.0621e+00,  2.5501e-01,  6.2826e-01, -2.0507e+00,\n",
       "          -1.7579e+00],\n",
       "         [-2.9659e-02, -2.1765e+00, -3.5914e-01,  1.2775e+00,  1.9087e+00,\n",
       "           1.3630e+00, -9.6167e-01, -1.0200e-01, -1.4289e-01,  4.5776e-01,\n",
       "          -1.7046e+00,  2.2689e+00, -3.9737e-01,  1.1532e-01, -2.1950e-02,\n",
       "           3.6577e-01, -5.8070e-01,  2.2751e+00, -7.7381e-01, -7.6433e-02,\n",
       "           1.7128e+00, -3.3281e-01,  1.9989e+00,  1.0601e-01, -1.4411e-01,\n",
       "           1.0164e+00],\n",
       "         [-5.4605e-01, -1.0962e-01, -7.3364e-02,  2.0355e-01, -9.3468e-01,\n",
       "          -2.1874e-01,  1.7043e+00, -7.2178e-01,  1.9948e+00, -4.4615e-01,\n",
       "           6.2241e-01, -1.1054e-03,  1.3621e-01,  9.2338e-01, -8.1252e-01,\n",
       "          -4.5644e-01, -5.4807e-02,  6.6622e-01, -4.7007e-01,  6.7823e-01,\n",
       "           2.3303e-01, -6.5967e-01, -8.8480e-01,  4.5701e-02, -9.3617e-01,\n",
       "           7.4276e-01],\n",
       "         [ 1.5966e+00, -1.8014e-01, -6.3399e-01,  3.2062e-01, -5.3404e-02,\n",
       "           1.2878e+00, -2.6880e-01, -2.8349e-01, -3.2343e-01, -9.2792e-01,\n",
       "          -1.6916e+00, -2.3211e+00, -1.7980e+00, -1.8690e+00, -1.5336e+00,\n",
       "          -5.3563e-01,  1.9386e-01, -3.6389e-01,  1.3982e+00, -6.1325e-01,\n",
       "          -3.8367e-01, -1.0027e+00, -1.0167e+00, -6.5375e-01, -1.1031e+00,\n",
       "          -8.3272e-01]], device='cuda:0'),\n",
       " tensor([[ 0.7595,  0.8192,  0.7636,  0.8539,  0.8597,  0.9098,  0.8604,  0.9187,\n",
       "           0.9203,  0.9489,  1.0096,  0.9858,  0.9976,  1.0070,  1.0160,  1.0512,\n",
       "           1.0612,  1.0783,  1.0835,  1.0629,  1.0786,  1.1606,  1.1908,  1.2210,\n",
       "           1.2826,  1.3564],\n",
       "         [ 0.8703,  0.8575,  0.8238,  0.8093,  0.8425,  0.9136,  0.8834,  0.9303,\n",
       "           0.8991,  0.8966,  0.9069,  0.8936,  0.8691,  0.8510,  0.8454,  0.9422,\n",
       "           0.9714,  0.9559,  0.9496,  0.9420,  0.9544,  0.9559,  0.9374,  0.9393,\n",
       "           0.9269,  0.9199],\n",
       "         [ 0.8941,  0.8901,  0.8874,  0.8485,  0.8484,  0.8317,  0.8755,  0.8465,\n",
       "           0.8435,  0.8242,  0.7926,  0.8049,  0.7766,  0.8349,  0.8724,  0.8600,\n",
       "           0.8708,  0.8665,  0.8780,  0.8921,  0.9027,  0.9026,  0.8949,  0.9273,\n",
       "           0.9191,  0.9257],\n",
       "         [ 0.6402,  0.6277,  0.6132,  0.5808,  0.5550,  0.5351,  0.5422,  0.5302,\n",
       "           0.5488,  0.5244,  0.4841,  0.4257,  0.3623,  0.3767,  0.3595,  0.3416,\n",
       "           0.2768,  0.2353,  0.2031,  0.1606,  0.1735,  0.1031,  0.1241,  0.0668,\n",
       "          -0.0234, -0.0478],\n",
       "         [ 0.8141,  0.8066,  0.8004,  0.7950,  0.8213,  0.8590,  0.9091,  0.8935,\n",
       "           0.9023,  0.8936,  0.8842,  0.9072,  0.9090,  0.9075,  0.8930,  0.8650,\n",
       "           0.8452,  0.8405,  0.8508,  0.8439,  0.8466,  0.8598,  0.9272,  0.9392,\n",
       "           0.9133,  0.9050],\n",
       "         [ 1.1073,  1.0851,  1.0827,  1.0876,  1.1135,  1.1226,  1.1813,  1.2005,\n",
       "           1.2379,  1.2339,  1.2076,  1.1959,  1.1754,  1.2321,  1.2689,  1.2838,\n",
       "           1.2843,  1.3674,  1.3921,  1.4147,  1.4831,  1.5165,  1.5459,  1.5526,\n",
       "           1.5375,  1.5988],\n",
       "         [ 0.8515,  0.8385,  0.8154,  0.8045,  0.8022,  0.7839,  0.8646,  0.8338,\n",
       "           0.8266,  0.8337,  0.8503,  0.8532,  0.8362,  0.8152,  0.8119,  0.7724,\n",
       "           0.7583,  0.7492,  0.7641,  0.7702,  0.8075,  0.8159,  0.8036,  0.7481,\n",
       "           0.7455,  0.7149],\n",
       "         [ 0.7672,  0.7672,  0.7471,  0.7230,  0.7831,  0.7577,  0.7494,  0.7371,\n",
       "           0.7356,  0.7440,  0.7367,  0.7037,  0.6572,  0.6167,  0.6048,  0.5992,\n",
       "           0.5979,  0.5804,  0.5926,  0.6228,  0.6235,  0.6021,  0.5888,  0.6071,\n",
       "           0.5588,  0.5636],\n",
       "         [ 0.6707,  0.6597,  0.7276,  0.7014,  0.7631,  0.7578,  0.8160,  0.7915,\n",
       "           0.7987,  0.7786,  0.7943,  0.7733,  0.8262,  0.8293,  0.8115,  0.7912,\n",
       "           0.7830,  0.7934,  0.7872,  0.7964,  0.8568,  0.8310,  0.8229,  0.7981,\n",
       "           0.8414,  0.8319],\n",
       "         [ 1.1006,  1.0889,  1.0964,  1.1041,  1.1328,  1.1612,  1.1734,  1.2039,\n",
       "           1.2146,  1.2665,  1.2907,  1.2991,  1.2951,  1.3206,  1.3561,  1.4052,\n",
       "           1.4100,  1.5000,  1.6046,  1.6415,  1.7232,  1.7309,  1.8227,  1.8498,\n",
       "           1.8979,  1.9895],\n",
       "         [ 0.7972,  0.7994,  0.7847,  0.7652,  0.8101,  0.7999,  0.7926,  0.7995,\n",
       "           0.7846,  0.8095,  0.8030,  0.7853,  0.7688,  0.7603,  0.7563,  0.7876,\n",
       "           0.7948,  0.7916,  0.7923,  0.7981,  0.7945,  0.7926,  0.7976,  0.7557,\n",
       "           0.7904,  0.8307],\n",
       "         [ 0.9075,  0.8876,  0.8455,  0.8119,  0.7933,  0.8586,  0.8288,  0.8217,\n",
       "           0.8245,  0.8208,  0.8347,  0.8949,  0.8952,  0.9021,  0.9266,  0.9838,\n",
       "           0.9762,  0.9836,  0.9745,  0.9456,  0.9655,  0.9423,  0.9452,  0.9305,\n",
       "           0.9614,  0.9393],\n",
       "         [ 0.4773,  0.4438,  0.4197,  0.3737,  0.3875,  0.4235,  0.3971,  0.4130,\n",
       "           0.4018,  0.4058,  0.3845,  0.3387,  0.2741,  0.2255,  0.1592,  0.1616,\n",
       "           0.1448,  0.0973,  0.0493,  0.0042,  0.0261, -0.0062,  0.0047,  0.0279,\n",
       "          -0.0369, -0.0921],\n",
       "         [ 0.8738,  0.8049,  0.7956,  0.8401,  0.9054,  0.9527,  0.9236,  0.9228,\n",
       "           0.9207,  0.9383,  0.8848,  0.9619,  0.9514,  0.9577,  0.9595,  0.9741,\n",
       "           0.9576,  1.0348,  1.0120,  1.0120,  1.0708,  1.0624,  1.1306,  1.1366,\n",
       "           1.1344,  1.1704],\n",
       "         [ 0.8339,  0.8329,  0.8330,  0.8423,  0.8141,  0.8095,  0.8680,  0.8468,\n",
       "           0.9149,  0.9028,  0.9258,  0.9283,  0.9353,  0.9682,  0.9440,  0.9316,\n",
       "           0.9323,  0.9568,  0.9439,  0.9687,  0.9789,  0.9598,  0.9332,  0.9373,\n",
       "           0.9091,  0.9360],\n",
       "         [ 0.7705,  0.7671,  0.7489,  0.7619,  0.7627,  0.8076,  0.8013,  0.7945,\n",
       "           0.7864,  0.7585,  0.7055,  0.6318,  0.5753,  0.5165,  0.4686,  0.4536,\n",
       "           0.4625,  0.4531,  0.5016,  0.4840,  0.4739,  0.4435,  0.4127,  0.3938,\n",
       "           0.3601,  0.3353]], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl.trainer.utils import first_true_indices\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_data(question):\n",
    "    #====answer====\n",
    "    answer = generate(model_actor,\n",
    "                      input_ids=question,\n",
    "                      pad_token_id=tokenizer.pad_token_id,\n",
    "                      eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    answer = answer[:, question.shape[1]:]\n",
    "\n",
    "    #求结束位置\n",
    "    ends = first_true_indices(answer == tokenizer.pad_token_id).tolist()\n",
    "\n",
    "    #====prob,value====\n",
    "    prob_old = get_logprob(model_actor, question, answer)\n",
    "    prob_ref = get_logprob(model_actor_ref, question, answer)\n",
    "    value_old = get_value(model_critic, question, answer)\n",
    "    #这里因为有可能取到最后一个字,所以不能偏移,如果偏移的话,最后一个字的值会被裁剪掉.\n",
    "    value_ref = get_value(model_critic_ref, question, answer, shift=False)\n",
    "\n",
    "    #end以后的值value归零\n",
    "    for i, end in enumerate(ends):\n",
    "        prob_old[i, end:] = 1.0\n",
    "        prob_ref[i, end:] = 1.0\n",
    "        value_old[i, end + 1:] = 0.0\n",
    "\n",
    "    #====reward====\n",
    "    reward = []\n",
    "    for i, end in enumerate(ends):\n",
    "        #没有eos符号的,置为-1\n",
    "        if tokenizer.eos_token_id not in answer[i]:\n",
    "            #reward.append(-1)\n",
    "            #continue\n",
    "            pass\n",
    "        #取最后一个字的value作为reward\n",
    "        reward.append(value_ref[i, end + question.shape[1] - 1])\n",
    "    reward = torch.FloatTensor(reward).to(device)\n",
    "\n",
    "    #====advantage====\n",
    "    #计算kl散度\n",
    "    reward_kl = -0.05 * (prob_old - prob_ref)\n",
    "\n",
    "    #把reward加在最后一个字的kl散度上\n",
    "    for i, end in enumerate(ends):\n",
    "        if end == len(answer[i]):\n",
    "            end = -1\n",
    "        #assert end == -1\n",
    "\n",
    "        reward_kl[i, end] += reward[i]\n",
    "\n",
    "    advantage = get_advantage(value_old, reward_kl)\n",
    "    returns = advantage + value_old\n",
    "\n",
    "    #标准化,保持数值稳定\n",
    "    select = torch.cat([adv[:end] for adv, end in zip(advantage, ends)])\n",
    "    advantage = (advantage - select.mean()) / (select.var() + 1e-8)**0.5\n",
    "\n",
    "    #end以后的值归零\n",
    "    for i, end in enumerate(ends):\n",
    "        advantage[i, end:] = 0\n",
    "\n",
    "    return question, answer, ends, prob_old, value_old, advantage, returns\n",
    "\n",
    "\n",
    "get_data(next(iter(loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479d1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(question, answer, ends, prob_old, value_old, advantage, returns):\n",
    "    for _ in range(4):\n",
    "        #重新计算value和prob\n",
    "        prob_new = get_logprob(model_actor, question, answer)\n",
    "        value_new = get_value(model_critic, question, answer)\n",
    "\n",
    "        #end以后的值value归零\n",
    "        for i, end in enumerate(ends):\n",
    "            prob_new[i, end:] = 1.0\n",
    "            value_new[i, end + 1:] = 0\n",
    "\n",
    "        #计算critic部分的loss\n",
    "        value_clip = torch.clamp(value_new, value_old - 0.2, value_old + 0.2)\n",
    "        loss_vf1 = (value_new - returns)**2\n",
    "        loss_vf2 = (value_clip - returns)**2\n",
    "        loss_vf = torch.max(loss_vf1, loss_vf2)\n",
    "\n",
    "        #计算actor部分的loss\n",
    "        ratio = (prob_new - prob_old).exp()\n",
    "        loss_pg1 = -advantage * ratio\n",
    "        loss_pg2 = -advantage * torch.clamp(ratio, 0.8, 1.2)\n",
    "        loss_pg = torch.max(loss_pg1, loss_pg2)\n",
    "\n",
    "        #丢弃end之后的部分\n",
    "        loss_vf = [xi[:end + 1] for xi, end in zip(loss_vf, ends)]\n",
    "        loss_pg = [xi[:end + 1] for xi, end in zip(loss_pg, ends)]\n",
    "        loss_vf = torch.cat(loss_vf).mean()\n",
    "        loss_pg = torch.cat(loss_pg).mean()\n",
    "\n",
    "        loss = loss_pg + 0.05 * loss_vf\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "train(*get_data(next(iter(loader))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d07c811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'question': 'B177+9401=', 'gen': '9578+4601=14179E'}\n",
      "200\n",
      "{'question': 'B2401+6696=9097+7166=', 'gen': '16263E'}\n",
      "400\n",
      "{'question': 'B8995+5001=', 'gen': '13996E'}\n",
      "600\n",
      "{'question': 'B5843+6778=', 'gen': '12621E'}\n",
      "800\n",
      "{'question': 'B3193+6516=', 'gen': '9709E'}\n",
      "1000\n",
      "{'question': 'B4075+6829=10904+6940=', 'gen': '17844E'}\n",
      "1200\n",
      "{'question': 'B7498+7584=15082+590=', 'gen': '15672E'}\n",
      "1400\n",
      "{'question': 'B9685+5812=15497+1720=17217+140=', 'gen': '17357E'}\n",
      "1600\n",
      "{'question': 'B3977+2479=6456+6597=', 'gen': '13053E'}\n",
      "1800\n",
      "{'question': 'B3643+6348=9991+4412=14403+5166=', 'gen': '19569E'}\n",
      "2000\n",
      "{'question': 'B8540+4172=12712+4179=16891+9758=', 'gen': '26649E'}\n",
      "2200\n",
      "{'question': 'B4614+5868=', 'gen': '10482E'}\n",
      "2400\n",
      "{'question': 'B7421+9344=16765+4075=20840+1330=', 'gen': '22170E'}\n",
      "2600\n",
      "{'question': 'B8788+5388=', 'gen': '14176E'}\n",
      "2800\n",
      "{'question': 'B227+7443=', 'gen': '7670E'}\n",
      "3000\n",
      "{'question': 'B8202+5517=13719+8693=', 'gen': '22412E'}\n",
      "3200\n",
      "{'question': 'B7374+222=7596+4547=12143+6562=', 'gen': '18705E'}\n",
      "3400\n",
      "{'question': 'B5840+3864=9704+1213=10917+631=', 'gen': '11548E'}\n",
      "3600\n",
      "{'question': 'B9330+9774=19104+1682=20786+5182=', 'gen': '25968E'}\n",
      "3800\n",
      "{'question': 'B4410+7953=12363+1233=', 'gen': '13596E'}\n",
      "4000\n",
      "{'question': 'B7437+3949=11386+2376=', 'gen': '13762E'}\n",
      "4200\n",
      "{'question': 'B7085+8674=', 'gen': '15759E'}\n",
      "4400\n",
      "{'question': 'B3997+7352=11349+8491=19840+9881=', 'gen': '29721E'}\n",
      "4600\n",
      "{'question': 'B1790+5050=', 'gen': '6840E'}\n",
      "4800\n",
      "{'question': 'B3607+2409=6016+3414=9430+9910=', 'gen': '19340E'}\n",
      "5000\n",
      "{'question': 'B8267+2749=11016+9059=20075+2866=', 'gen': '22941E'}\n",
      "5200\n",
      "{'question': 'B8995+837=9832+7495=17327+102=', 'gen': '17429E'}\n",
      "5400\n",
      "{'question': 'B7928+3990=', 'gen': '11918E'}\n",
      "5600\n",
      "{'question': 'B1820+9601=', 'gen': '11421E'}\n",
      "5800\n",
      "{'question': 'B828+7141=7969+3326=', 'gen': '11295E'}\n",
      "6000\n",
      "{'question': 'B4244+1318=', 'gen': '5562E'}\n",
      "6200\n",
      "{'question': 'B9093+203=9296+8842=18138+5307=', 'gen': '23445E'}\n",
      "6400\n",
      "{'question': 'B4025+2729=6754+7488=', 'gen': '14242E'}\n",
      "6600\n",
      "{'question': 'B1720+60=1780+327=2107+4105=', 'gen': '6212E'}\n",
      "6800\n",
      "{'question': 'B5509+256=', 'gen': '5765+4777=10542E'}\n",
      "7000\n",
      "{'question': 'B4362+6109=10471+2986=13457+3097=', 'gen': '16554E'}\n",
      "7200\n",
      "{'question': 'B4373+3824=8197+7360=', 'gen': '15557E'}\n",
      "7400\n",
      "{'question': 'B5749+2589=8338+5337=', 'gen': '13675E'}\n",
      "7600\n",
      "{'question': 'B4328+8459=', 'gen': '12787E'}\n",
      "7800\n",
      "{'question': 'B6159+22=', 'gen': '6180E'}\n",
      "8000\n",
      "{'question': 'B6147+42=6189+8418=', 'gen': '14607E'}\n",
      "8200\n",
      "{'question': 'B4156+9558=', 'gen': '13714E'}\n",
      "8400\n",
      "{'question': 'B3316+2418=', 'gen': '5734E'}\n",
      "8600\n",
      "{'question': 'B5724+7601=13325+3792=', 'gen': '17117E'}\n",
      "8800\n",
      "{'question': 'B8488+3359=', 'gen': '11847E'}\n",
      "9000\n",
      "{'question': 'B6775+1778=8553+3493=', 'gen': '12046E'}\n",
      "9200\n",
      "{'question': 'B7130+1174=8304+2782=11086+9810=', 'gen': '20896E'}\n",
      "9400\n",
      "{'question': 'B2729+4179=6908+8825=15733+8913=', 'gen': '24646E'}\n",
      "9600\n",
      "{'question': 'B8947+7125=', 'gen': '16072E'}\n",
      "9800\n",
      "{'question': 'B8805+5486=14291+8157=', 'gen': '22448E'}\n",
      "10000\n",
      "{'question': 'B44+2467=2511+1679=4190+8366=', 'gen': '12556E'}\n",
      "10200\n",
      "{'question': 'B5794+29=5823+9427=', 'gen': '15250E'}\n",
      "10400\n",
      "{'question': 'B9449+2978=12427+5341=17768+1432=', 'gen': '19200E'}\n",
      "10600\n",
      "{'question': 'B877+5929=6806+9865=', 'gen': '16671E'}\n",
      "10800\n",
      "{'question': 'B3251+7767=11018+3050=', 'gen': '14068E'}\n",
      "11000\n",
      "{'question': 'B166+2331=2497+8733=', 'gen': '11230E'}\n",
      "11200\n",
      "{'question': 'B9776+9417=', 'gen': '19193E'}\n",
      "11400\n",
      "{'question': 'B5184+1229=', 'gen': '6413E'}\n",
      "11600\n",
      "{'question': 'B2406+5921=8327+1182=', 'gen': '9509E'}\n",
      "11800\n",
      "{'question': 'B2605+230=', 'gen': '2835E'}\n",
      "12000\n",
      "{'question': 'B3717+9050=12767+8744=21511+6539=', 'gen': '28050E'}\n",
      "12200\n",
      "{'question': 'B7191+5834=', 'gen': '13025E'}\n",
      "12400\n",
      "{'question': 'B9571+4086=13657+898=', 'gen': '14555E'}\n",
      "12600\n",
      "{'question': 'B5466+3129=8595+2424=11019+9744=', 'gen': '20763E'}\n",
      "12800\n",
      "{'question': 'B8240+3411=11651+1983=13634+7441=', 'gen': '21075E'}\n",
      "13000\n",
      "{'question': 'B5383+990=6373+232=', 'gen': '6605E'}\n",
      "13200\n",
      "{'question': 'B9685+7349=17034+3704=', 'gen': '20738E'}\n",
      "13400\n",
      "{'question': 'B1113+192=1305+4726=6031+7941=', 'gen': '13972E'}\n",
      "13600\n",
      "{'question': 'B6911+1246=', 'gen': '8157E'}\n",
      "13800\n",
      "{'question': 'B5083+7232=12315+5423=17738+9418=', 'gen': '27156E'}\n",
      "14000\n",
      "{'question': 'B2173+1380=3553+3200=', 'gen': '6753E'}\n",
      "14200\n",
      "{'question': 'B6529+1003=7532+4694=12226+6465=', 'gen': '18691E'}\n",
      "14400\n",
      "{'question': 'B2022+279=', 'gen': '2201E'}\n",
      "14600\n",
      "{'question': 'B1742+651=2393+3286=5679+557=', 'gen': '6236E'}\n",
      "14800\n",
      "{'question': 'B4387+9501=13888+5063=18951+7387=', 'gen': '26338E'}\n",
      "15000\n",
      "{'question': 'B3525+4741=', 'gen': '8266E'}\n",
      "15200\n",
      "{'question': 'B4564+9335=13899+1248=', 'gen': '15147E'}\n",
      "15400\n",
      "{'question': 'B8489+5693=', 'gen': '14182E'}\n",
      "15600\n",
      "{'question': 'B7501+5059=12560+7970=20530+4614=', 'gen': '25144E'}\n",
      "15800\n",
      "{'question': 'B6597+9050=15647+4670=', 'gen': '20317+4777=25094E'}\n",
      "16000\n",
      "{'question': 'B7846+1746=', 'gen': '9592E'}\n",
      "16200\n",
      "{'question': 'B9081+9548=18629+8093=26722+4764=', 'gen': '31486E'}\n",
      "16400\n",
      "{'question': 'B9637+1475=', 'gen': '11112E'}\n",
      "16600\n",
      "{'question': 'B3087+8857=11944+8221=20165+3199=', 'gen': '23364E'}\n",
      "16800\n",
      "{'question': 'B436+6913=', 'gen': '7349E'}\n",
      "17000\n",
      "{'question': 'B9812+8193=', 'gen': '18005E'}\n",
      "17200\n",
      "{'question': 'B2198+1697=', 'gen': '3895E'}\n",
      "17400\n",
      "{'question': 'B2866+8226=11092+9776=20868+7026=', 'gen': '27894E'}\n",
      "17600\n",
      "{'question': 'B6518+6416=12934+9100=', 'gen': '22034E'}\n",
      "17800\n",
      "{'question': 'B8531+9892=', 'gen': '18423E'}\n",
      "18000\n",
      "{'question': 'B331+3923=', 'gen': '4254E'}\n",
      "18200\n",
      "{'question': 'B4649+1092=5741+3665=', 'gen': '9406E'}\n",
      "18400\n",
      "{'question': 'B5463+2012=', 'gen': '7475E'}\n",
      "18600\n",
      "{'question': 'B5419+8356=13775+2433=16208+464=', 'gen': '16672E'}\n",
      "18800\n",
      "{'question': 'B8501+9456=', 'gen': '17957E'}\n",
      "19000\n",
      "{'question': 'B8095+99=', 'gen': '8199E'}\n",
      "19200\n",
      "{'question': 'B2037+150=2187+3803=', 'gen': '5990E'}\n",
      "19400\n",
      "{'question': 'B4353+1691=', 'gen': '6044E'}\n",
      "19600\n",
      "{'question': 'B7327+4615=', 'gen': '11942E'}\n",
      "19800\n",
      "{'question': 'B8539+3532=12071+8258=20329+407=', 'gen': '20736E'}\n",
      "20000\n",
      "{'question': 'B4936+6333=11269+8100=19369+6490=', 'gen': '25859E'}\n",
      "20200\n",
      "{'question': 'B5433+9732=', 'gen': '15165E'}\n",
      "20400\n",
      "{'question': 'B5137+2545=7682+14=7696+8848=', 'gen': '16544E'}\n",
      "20600\n",
      "{'question': 'B8398+2801=11199+8270=19469+3232=', 'gen': '22701E'}\n",
      "20800\n",
      "{'question': 'B7832+9913=', 'gen': '17745E'}\n",
      "21000\n",
      "{'question': 'B6620+1445=8065+4982=13047+4091=', 'gen': '17138E'}\n",
      "21200\n",
      "{'question': 'B2900+9115=12015+1889=', 'gen': '13904E'}\n",
      "21400\n",
      "{'question': 'B5136+498=5634+7440=', 'gen': '13074E'}\n",
      "21600\n",
      "{'question': 'B5912+6057=', 'gen': '11969E'}\n",
      "21800\n",
      "{'question': 'B2232+2164=4396+3818=', 'gen': '8214E'}\n",
      "22000\n",
      "{'question': 'B9260+6054=', 'gen': '15314E'}\n",
      "22200\n",
      "{'question': 'B7017+9157=', 'gen': '16174E'}\n",
      "22400\n",
      "{'question': 'B6526+3469=', 'gen': '9995E'}\n",
      "22600\n",
      "{'question': 'B9218+4559=13777+9518=', 'gen': '23295E'}\n",
      "22800\n",
      "{'question': 'B7543+5923=', 'gen': '13466E'}\n",
      "23000\n",
      "{'question': 'B263+4579=', 'gen': '4842E'}\n",
      "23200\n",
      "{'question': 'B5033+8246=13279+3877=17156+2807=', 'gen': '19963E'}\n",
      "23400\n",
      "{'question': 'B2350+1865=4215+2987=7202+2117=', 'gen': '9319E'}\n",
      "23600\n",
      "{'question': 'B3434+3478=', 'gen': '6912E'}\n",
      "23800\n",
      "{'question': 'B5394+3690=', 'gen': '9084E'}\n",
      "24000\n",
      "{'question': 'B5711+8049=13760+2804=16564+3980=', 'gen': '20544E'}\n",
      "24200\n",
      "{'question': 'B3024+4327=', 'gen': '7351E'}\n",
      "24400\n",
      "{'question': 'B5366+7324=12690+392=13082+702=', 'gen': '13784E'}\n",
      "24600\n",
      "{'question': 'B8361+5838=14199+4987=', 'gen': '19186E'}\n",
      "24800\n",
      "{'question': 'B4309+1118=', 'gen': '5427E'}\n",
      "25000\n",
      "{'question': 'B4066+7746=', 'gen': '11812E'}\n",
      "25200\n",
      "{'question': 'B4986+2027=7013+8111=15124+1149=', 'gen': '16273E'}\n",
      "25400\n",
      "{'question': 'B8077+3159=', 'gen': '11236E'}\n",
      "25600\n",
      "{'question': 'B5045+9854=14899+5015=19914+1035=', 'gen': '20949E'}\n",
      "25800\n",
      "{'question': 'B1793+6952=8745+649=', 'gen': '9394E'}\n",
      "26000\n",
      "{'question': 'B428+951=', 'gen': '1379E'}\n",
      "26200\n",
      "{'question': 'B7010+9480=16490+1120=17610+1566=', 'gen': '19176E'}\n",
      "26400\n",
      "{'question': 'B4530+1792=6322+4204=', 'gen': '10526E'}\n",
      "26600\n",
      "{'question': 'B1205+4942=6147+7970=', 'gen': '14117E'}\n",
      "26800\n",
      "{'question': 'B4012+6956=10968+2745=13713+2321=', 'gen': '16034E'}\n",
      "27000\n",
      "{'question': 'B2039+4023=6062+7756=13818+6467=', 'gen': '20285E'}\n",
      "27200\n",
      "{'question': 'B3994+3014=7008+5059=12067+3250=', 'gen': '15317E'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27400\n",
      "{'question': 'B1299+8578=9877+7841=', 'gen': '17718E'}\n",
      "27600\n",
      "{'question': 'B6248+9153=15401+5944=21345+8830=', 'gen': '30175E'}\n",
      "27800\n",
      "{'question': 'B7687+2624=', 'gen': '10311E'}\n",
      "28000\n",
      "{'question': 'B843+276=1119+4278=', 'gen': '5397E'}\n",
      "28200\n",
      "{'question': 'B5330+1040=6370+8668=15038+2427=', 'gen': '17465E'}\n",
      "28400\n",
      "{'question': 'B9591+7655=17246+1044=', 'gen': '18290E'}\n",
      "28600\n",
      "{'question': 'B2744+2624=5368+8623=', 'gen': '13991E'}\n",
      "28800\n",
      "{'question': 'B6018+4965=10983+2851=13834+163=', 'gen': '13997E'}\n",
      "29000\n",
      "{'question': 'B9630+296=', 'gen': '9926E'}\n",
      "29200\n",
      "{'question': 'B5850+4378=10228+3933=', 'gen': '14161E'}\n",
      "29400\n",
      "{'question': 'B4574+4863=9437+8197=', 'gen': '17634E'}\n",
      "29600\n",
      "{'question': 'B4577+9369=13946+1717=15663+1550=', 'gen': '17213E'}\n",
      "29800\n",
      "{'question': 'B7411+5341=12752+2707=15459+9494=', 'gen': '24953E'}\n",
      "30000\n",
      "{'question': 'B359+3569=3928+9223=', 'gen': '13151E'}\n",
      "30200\n",
      "{'question': 'B1821+6868=', 'gen': '8689E'}\n",
      "30400\n",
      "{'question': 'B7902+210=8112+5522=', 'gen': '13634E'}\n",
      "30600\n",
      "{'question': 'B9329+6677=', 'gen': '16006E'}\n",
      "30800\n",
      "{'question': 'B6950+3433=', 'gen': '10383E'}\n",
      "31000\n",
      "{'question': 'B4810+6348=11158+2440=', 'gen': '13598E'}\n",
      "31200\n",
      "{'question': 'B9002+3109=12111+3933=', 'gen': '16044E'}\n",
      "31400\n",
      "{'question': 'B1337+7244=8581+41=', 'gen': '8622E'}\n",
      "31600\n",
      "{'question': 'B9212+2325=11537+501=', 'gen': '12038E'}\n",
      "31800\n",
      "{'question': 'B9237+7097=16334+3424=19758+5698=', 'gen': '25456E'}\n",
      "32000\n",
      "{'question': 'B4536+6453=', 'gen': '10989E'}\n",
      "32200\n",
      "{'question': 'B7123+3312=10435+5202=15637+2226=', 'gen': '17863E'}\n",
      "32400\n",
      "{'question': 'B4996+5907=10903+6569=17472+421=', 'gen': '17893E'}\n",
      "32600\n",
      "{'question': 'B8613+4025=', 'gen': '12638E'}\n",
      "32800\n",
      "{'question': 'B464+2487=2951+4990=7941+8609=', 'gen': '16550E'}\n",
      "33000\n",
      "{'question': 'B2626+3839=6465+1828=8293+922=', 'gen': '9215E'}\n",
      "33200\n",
      "{'question': 'B6488+6980=', 'gen': '13468E'}\n",
      "33400\n",
      "{'question': 'B1057+4650=5707+5868=', 'gen': '11575E'}\n",
      "33600\n",
      "{'question': 'B2418+911=3329+3956=', 'gen': '7285E'}\n",
      "33800\n",
      "{'question': 'B9629+2762=12391+4386=', 'gen': '16777E'}\n",
      "34000\n",
      "{'question': 'B8440+7580=16020+7611=', 'gen': '23631E'}\n",
      "34200\n",
      "{'question': 'B2552+8385=10937+7499=18436+8026=', 'gen': '26462E'}\n",
      "34400\n",
      "{'question': 'B4726+4667=', 'gen': '9393E'}\n",
      "34600\n",
      "{'question': 'B2923+6736=', 'gen': '9659E'}\n",
      "34800\n",
      "{'question': 'B2104+433=2537+6641=', 'gen': '9178E'}\n",
      "35000\n",
      "{'question': 'B3228+445=3673+4703=8376+4452=', 'gen': '12828E'}\n",
      "35200\n",
      "{'question': 'B4074+6634=10708+7352=18060+6349=', 'gen': '24409E'}\n",
      "35400\n",
      "{'question': 'B3273+6695=9968+8043=18011+3373=', 'gen': '21384E'}\n",
      "35600\n",
      "{'question': 'B9911+4979=', 'gen': '14890E'}\n",
      "35800\n",
      "{'question': 'B6324+7180=', 'gen': '13504E'}\n",
      "36000\n",
      "{'question': 'B5209+2158=', 'gen': '7367E'}\n",
      "36200\n",
      "{'question': 'B3854+330=4184+8=', 'gen': '4192+4777=8969E'}\n",
      "36400\n",
      "{'question': 'B5151+6584=', 'gen': '11735E'}\n",
      "36600\n",
      "{'question': 'B936+1021=1957+85=', 'gen': '2042E'}\n",
      "36800\n",
      "{'question': 'B7596+3855=', 'gen': '11451E'}\n",
      "37000\n",
      "{'question': 'B8559+2981=11540+9460=21000+9487=', 'gen': '30487E'}\n",
      "37200\n",
      "{'question': 'B4371+9215=13586+9309=22895+1255=', 'gen': '24150E'}\n",
      "37400\n",
      "{'question': 'B9880+6670=16550+6777=23327+6049=', 'gen': '29376E'}\n",
      "37600\n",
      "{'question': 'B1960+9213=', 'gen': '11173E'}\n",
      "37800\n",
      "{'question': 'B3663+9094=12757+4511=', 'gen': '17268+4777=22045E'}\n",
      "38000\n",
      "{'question': 'B9957+2647=', 'gen': '12604E'}\n",
      "38200\n",
      "{'question': 'B7146+9182=', 'gen': '16328E'}\n",
      "38400\n",
      "{'question': 'B8210+5118=13328+5420=18748+4986=', 'gen': '23734E'}\n",
      "38600\n",
      "{'question': 'B1881+6109=7990+7134=15124+4080=', 'gen': '19204E'}\n",
      "38800\n",
      "{'question': 'B4688+4511=9199+5723=', 'gen': '14923E'}\n",
      "39000\n",
      "{'question': 'B5434+2619=', 'gen': '8053E'}\n",
      "39200\n",
      "{'question': 'B5367+3169=', 'gen': '8536E'}\n",
      "39400\n",
      "{'question': 'B4913+9338=', 'gen': '14251E'}\n",
      "39600\n",
      "{'question': 'B776+8086=8862+3152=', 'gen': '12014E'}\n",
      "39800\n",
      "{'question': 'B6607+7566=', 'gen': '14173E'}\n",
      "40000\n",
      "{'question': 'B5071+6102=', 'gen': '11173E'}\n",
      "40200\n",
      "{'question': 'B6260+9644=15904+293=16197+1867=', 'gen': '18064E'}\n",
      "40400\n",
      "{'question': 'B5543+96=5639+5760=11399+6133=', 'gen': '17532E'}\n",
      "40600\n",
      "{'question': 'B4831+2609=7440+6321=', 'gen': '13761E'}\n",
      "40800\n",
      "{'question': 'B1071+4498=5569+9048=14617+7911=', 'gen': '22528E'}\n",
      "41000\n",
      "{'question': 'B1349+4611=5960+4823=10783+2165=', 'gen': '12948E'}\n",
      "41200\n",
      "{'question': 'B1394+1820=', 'gen': '3214E'}\n",
      "41400\n",
      "{'question': 'B138+3889=4027+7557=', 'gen': '11584E'}\n",
      "41600\n",
      "{'question': 'B262+6455=6717+8875=15592+5665=', 'gen': '21257E'}\n",
      "41800\n",
      "{'question': 'B2769+462=', 'gen': '3231E'}\n",
      "42000\n",
      "{'question': 'B3679+5271=8950+826=9776+8258=', 'gen': '18034E'}\n",
      "42200\n",
      "{'question': 'B9981+5126=15107+7970=23077+2929=', 'gen': '26006E'}\n",
      "42400\n",
      "{'question': 'B701+1564=2265+9894=', 'gen': '12159E'}\n",
      "42600\n",
      "{'question': 'B5183+2642=7825+4383=', 'gen': '12208E'}\n",
      "42800\n",
      "{'question': 'B4773+3787=8560+1246=9806+1804=', 'gen': '11610E'}\n",
      "43000\n",
      "{'question': 'B4318+8141=12459+7573=20032+6398=', 'gen': '26430E'}\n",
      "43200\n",
      "{'question': 'B6276+6460=', 'gen': '12736E'}\n",
      "43400\n",
      "{'question': 'B5026+9320=', 'gen': '14346E'}\n",
      "43600\n",
      "{'question': 'B5472+1845=7317+1170=8487+1743=', 'gen': '10230E'}\n",
      "43800\n",
      "{'question': 'B8681+25=8706+6165=14871+4441=', 'gen': '19312E'}\n",
      "44000\n",
      "{'question': 'B1651+2322=', 'gen': '3973E'}\n",
      "44200\n",
      "{'question': 'B4135+1531=5666+2819=', 'gen': '8485E'}\n",
      "44400\n",
      "{'question': 'B9837+8484=18321+1819=20140+5396=', 'gen': '25536E'}\n",
      "44600\n",
      "{'question': 'B3361+7385=10746+1381=', 'gen': '12127E'}\n",
      "44800\n",
      "{'question': 'B9219+8901=18120+719=18839+4178=', 'gen': '23017E'}\n",
      "45000\n",
      "{'question': 'B7770+8526=16296+526=16822+9948=', 'gen': '26770E'}\n",
      "45200\n",
      "{'question': 'B5091+7824=12915+6536=', 'gen': '19451E'}\n",
      "45400\n",
      "{'question': 'B5392+7087=12479+1855=14334+5010=', 'gen': '19344E'}\n",
      "45600\n",
      "{'question': 'B3955+2671=6626+5081=11707+8883=', 'gen': '20590E'}\n",
      "45800\n",
      "{'question': 'B7131+701=7832+5188=13020+2643=', 'gen': '15663E'}\n",
      "46000\n",
      "{'question': 'B8472+5397=13869+7430=', 'gen': '21299E'}\n",
      "46200\n",
      "{'question': 'B8511+4163=12674+9162=', 'gen': '21836+4777=26613E'}\n",
      "46400\n",
      "{'question': 'B1060+2240=', 'gen': '3300E'}\n",
      "46600\n",
      "{'question': 'B6656+1657=8313+2820=', 'gen': '11133E'}\n",
      "46800\n",
      "{'question': 'B8451+1871=10322+1865=12187+1150=', 'gen': '13337E'}\n",
      "47000\n",
      "{'question': 'B778+4729=5507+8238=13745+9676=', 'gen': '23421E'}\n",
      "47200\n",
      "{'question': 'B314+9950=10264+7849=', 'gen': '18113E'}\n",
      "47400\n",
      "{'question': 'B2392+2802=', 'gen': '5194E'}\n",
      "47600\n",
      "{'question': 'B9961+6533=16494+9897=26391+7213=', 'gen': '33604E'}\n",
      "47800\n",
      "{'question': 'B4142+9525=', 'gen': '13667E'}\n",
      "48000\n",
      "{'question': 'B2614+702=', 'gen': '3316E'}\n",
      "48200\n",
      "{'question': 'B3906+4419=', 'gen': '8325E'}\n",
      "48400\n",
      "{'question': 'B9656+3107=12763+2459=15222+5398=', 'gen': '20620E'}\n",
      "48600\n",
      "{'question': 'B65+5019=', 'gen': '5084E'}\n",
      "48800\n",
      "{'question': 'B1186+4800=5986+1887=7873+5029=', 'gen': '12902E'}\n",
      "49000\n",
      "{'question': 'B5306+7866=13172+639=13811+8006=', 'gen': '21817E'}\n",
      "49200\n",
      "{'question': 'B2479+2552=', 'gen': '5031E'}\n",
      "49400\n",
      "{'question': 'B3650+6882=10532+6531=17063+5094=', 'gen': '22157E'}\n",
      "49600\n",
      "{'question': 'B5404+1134=', 'gen': '6538E'}\n",
      "49800\n",
      "{'question': 'B9721+5672=', 'gen': '15393E'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5_0000):\n",
    "    train(*get_data(next(iter(loader))))\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        print(i)\n",
    "        input_ids = next(iter(loader))[0:1]\n",
    "\n",
    "        gen = generate(model_actor,\n",
    "                       input_ids=input_ids,\n",
    "                       pad_token_id=tokenizer.pad_token_id,\n",
    "                       eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "        question = tokenizer.decode(input_ids[0])\n",
    "        gen = tokenizer.decode(gen[0, input_ids.shape[1]:])\n",
    "\n",
    "        print({'question': question, 'gen': gen})\n",
    "\n",
    "torch.save(model_actor.to('cpu'), 'model/ppo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
