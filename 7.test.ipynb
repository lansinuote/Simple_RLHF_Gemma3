{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab835cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tokenizer at 0x7f8df48e4520>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "%run 1.tokenizer.ipynb\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb992d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, {'text': '4714+3261=', 'label': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 2.dataset.ipynb\n",
    "\n",
    "dataset = Dataset(negative_label=False, with_answer=False)\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2c4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 3.model.ipynb\n",
    "\n",
    "model_actor = torch.load('model/ppo', weights_only=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc57406a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'B9199+1350=', 'answer': 10549, 'gen': '10549E'}\n",
      "{'question': 'B999+8643=', 'answer': 9642, 'gen': '9642E'}\n",
      "{'question': 'B2302+1625=', 'answer': 3927, 'gen': '3927E'}\n",
      "{'question': 'B8277+3408=', 'answer': 11685, 'gen': '11685E'}\n",
      "{'question': 'B939+3877=', 'answer': 4816, 'gen': '4316E'}\n",
      "{'question': 'B8709+738=', 'answer': 9447, 'gen': '9447E'}\n",
      "{'question': 'B8602+3038=', 'answer': 11640, 'gen': '11640E'}\n",
      "{'question': 'B9418+6823=', 'answer': 16241, 'gen': '16241E'}\n",
      "{'question': 'B7894+1129=', 'answer': 9023, 'gen': '9023E'}\n",
      "{'question': 'B7220+2682=', 'answer': 9902, 'gen': '9902E'}\n",
      "{'question': 'B4999+1116=', 'answer': 6115, 'gen': '6115E'}\n",
      "{'question': 'B2613+8340=', 'answer': 10953, 'gen': '10953E'}\n",
      "{'question': 'B7482+5164=', 'answer': 12646, 'gen': '12646E'}\n",
      "{'question': 'B2012+4254=', 'answer': 6266, 'gen': '6266E'}\n",
      "{'question': 'B4528+4072=', 'answer': 8600, 'gen': '8600E'}\n",
      "{'question': 'B8456+75=', 'answer': 8531, 'gen': '8521E'}\n"
     ]
    }
   ],
   "source": [
    "#====question====\n",
    "question = random.choices(dataset, k=16)\n",
    "question = [i['text'] for i in question]\n",
    "\n",
    "question = tokenizer(question,\n",
    "                     device=device,\n",
    "                     add_bos_token=True,\n",
    "                     add_eos_token=False,\n",
    "                     padding_side='left')['input_ids']\n",
    "\n",
    "#====gen====\n",
    "gen = generate(model_actor,\n",
    "               input_ids=question,\n",
    "               pad_token_id=tokenizer.pad_token_id,\n",
    "               eos_token_id=tokenizer.eos_token_id)\n",
    "gen = gen[:, question.shape[1]:]\n",
    "\n",
    "for q, g in zip(question, gen):\n",
    "    q = tokenizer.decode(q)\n",
    "    g = tokenizer.decode(g)\n",
    "    a = q\n",
    "    a = a[a.index(tokenizer.bos_token) + 1:]\n",
    "    a = a[:a.index('=')]\n",
    "    a = int(eval(a))\n",
    "\n",
    "    print({'question': q, 'answer': a, 'gen': g})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
