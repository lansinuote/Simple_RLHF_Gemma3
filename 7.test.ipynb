{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab835cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tokenizer at 0x7eff61f4c760>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "%run 1.tokenizer.ipynb\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb992d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, {'text': '9092+3039=12131+2715=', 'label': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 2.dataset.ipynb\n",
    "\n",
    "dataset = Dataset(negative_label=False, with_answer=False)\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2c4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 3.model.ipynb\n",
    "\n",
    "model_actor = torch.load('model/ppo', weights_only=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc57406a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'B1505+1349=', 'gen': '2854E'}\n",
      "{'question': 'B2437+4395=', 'gen': '6832E'}\n",
      "{'question': 'B4520+9682=14202+6648=', 'gen': '20850E'}\n",
      "{'question': 'B1123+6282=7405+9943=', 'gen': '17348E'}\n",
      "{'question': 'B4272+2422=6694+1660=', 'gen': '8354E'}\n",
      "{'question': 'B1318+4655=5973+849=', 'gen': '6822E'}\n",
      "{'question': 'B7902+2157=10059+9503=19562+3976=', 'gen': '23538E'}\n",
      "{'question': 'B7561+6435=13996+8341=22337+3570=', 'gen': '25907E'}\n",
      "{'question': 'B5523+5655=11178+1142=12320+7360=', 'gen': '19680E'}\n",
      "{'question': 'B7646+2607=10253+5962=16215+6479=', 'gen': '22694E'}\n",
      "{'question': 'B6170+7481=', 'gen': '13651E'}\n",
      "{'question': 'B8975+7528=16503+7284=23787+7744=', 'gen': '31531E'}\n",
      "{'question': 'B427+9585=10012+4876=14888+6666=', 'gen': '21554E'}\n",
      "{'question': 'B5646+2024=7670+8478=16148+3802=', 'gen': '19950E'}\n",
      "{'question': 'B8332+553=8885+7602=16487+1586=', 'gen': '18073E'}\n",
      "{'question': 'B2801+482=3283+6315=9598+6933=', 'gen': '16539E'}\n"
     ]
    }
   ],
   "source": [
    "#====question====\n",
    "question = random.choices(dataset, k=16)\n",
    "question = [i['text'] for i in question]\n",
    "\n",
    "question = tokenizer(question,\n",
    "                     device=device,\n",
    "                     add_bos_token=True,\n",
    "                     add_eos_token=False,\n",
    "                     padding_side='left')['input_ids']\n",
    "\n",
    "#====gen====\n",
    "gen = generate(model_actor,\n",
    "               input_ids=question,\n",
    "               pad_token_id=tokenizer.pad_token_id,\n",
    "               eos_token_id=tokenizer.eos_token_id)\n",
    "gen = gen[:, question.shape[1]:]\n",
    "\n",
    "last_index = lambda lst, ele: len(lst) - lst[::-1].index(ele)\n",
    "\n",
    "for q, g in zip(question, gen):\n",
    "    q = tokenizer.decode(q)\n",
    "    g = tokenizer.decode(g)\n",
    "\n",
    "    print({'question': q, 'gen': g})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880825aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1670+5429=7099+2747=\n",
      "3 3924+3389=7313+8346=15659+8604=\n",
      "3 2719+6277=8996+3262=12258+953=\n",
      "2 826+1907=2733+5646=\n",
      "3 3922+1595=5517+1165=6682+4480=\n",
      "1 3701+1823=\n",
      "3 5799+8308=14107+5858=19965+2942=\n",
      "3 4707+9207=13914+4240=18154+8104=\n",
      "1 6662+8664=\n",
      "3 4694+7519=12213+6355=18568+9461=\n",
      "1 1152+7609=\n",
      "2 4902+4140=9042+9570=\n",
      "2 537+4710=5247+6295=\n",
      "3 9543+5018=14561+6831=21392+8808=\n",
      "1 2630+1753=\n",
      "2 7195+6947=14142+3261=\n"
     ]
    }
   ],
   "source": [
    "for i in random.choices(dataset, k=16):\n",
    "    print(i['text'].count('='),i['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba42f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent 1000+1000=\n",
      "q B1000+1000=\n",
      "gen [6, 4, 4, 4]\n",
      "gen [6, 4, 4, 4]\n",
      "gen 2000\n",
      "sent 1000+1000=2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ''\n",
    "\n",
    "\n",
    "def inference(q):\n",
    "    global sent\n",
    "\n",
    "    sent += q + '='\n",
    "\n",
    "    #限制最大轮次\n",
    "    if sent.count('=') > 3:\n",
    "        idx = sent.index('=') + 1\n",
    "        sent = sent[idx:]\n",
    "\n",
    "    print('sent', sent)\n",
    "\n",
    "    #编码\n",
    "    q = tokenizer([sent],\n",
    "                  device=device,\n",
    "                  add_bos_token=True,\n",
    "                  add_eos_token=False)['input_ids']\n",
    "\n",
    "    print('q', tokenizer.decode(q[0]))\n",
    "\n",
    "    #生成回答\n",
    "    gen = generate(model_actor,\n",
    "                   input_ids=q,\n",
    "                   pad_token_id=tokenizer.pad_token_id,\n",
    "                   eos_token_id=tokenizer.eos_token_id)\n",
    "    gen = gen[:, q.shape[1]:][0].tolist()\n",
    "\n",
    "    #切除eos\n",
    "    if tokenizer.eos_token_id in gen:\n",
    "        idx = gen.index(tokenizer.eos_token_id)\n",
    "        gen = gen[:idx]\n",
    "\n",
    "    print('gen', gen)\n",
    "\n",
    "    #如果生成了多余的对话,切除\n",
    "    if tokenizer.eq_token_id in gen:\n",
    "        idx = gen.index(tokenizer.eq_token_id)\n",
    "        gen = gen[:idx]\n",
    "\n",
    "    print('gen', gen)\n",
    "\n",
    "    gen = tokenizer.decode(gen)\n",
    "\n",
    "    print('gen', gen)\n",
    "\n",
    "    #拼接上下文\n",
    "    sent += gen\n",
    "\n",
    "    print('sent', sent)\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "inference('1000+1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e7c83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent 1000+1000=2000+500=\n",
      "q B1000+1000=2000+500=\n",
      "gen [6, 9, 4, 4]\n",
      "gen [6, 9, 4, 4]\n",
      "gen 2500\n",
      "sent 1000+1000=2000+500=2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2500'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('+500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1394a1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent 1000+1000=2000+500=2500+500=\n",
      "q B1000+1000=2000+500=2500+500=\n",
      "gen [7, 4, 4, 4]\n",
      "gen [7, 4, 4, 4]\n",
      "gen 3000\n",
      "sent 1000+1000=2000+500=2500+500=3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('+500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2316c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent 2000+500=2500+500=3000+500=\n",
      "q B2000+500=2500+500=3000+500=\n",
      "gen [7, 9, 4, 4]\n",
      "gen [7, 9, 4, 4]\n",
      "gen 3500\n",
      "sent 2000+500=2500+500=3000+500=3500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3500'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('+500')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
