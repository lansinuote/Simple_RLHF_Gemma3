{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab835cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tokenizer at 0x7f4064c5c550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "%run 1.tokenizer.ipynb\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb992d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, {'text': '323+7939=8262+945=9207+2570=', 'label': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 2.dataset.ipynb\n",
    "\n",
    "dataset = Dataset(negative_label=False, with_answer=False)\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2c4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 3.model.ipynb\n",
    "\n",
    "model_actor = torch.load('model/ppo', weights_only=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc57406a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'B9818+4065=13883+7277=21160+9723=', 'gen': '30883E'}\n",
      "{'question': 'B5354+5465=', 'gen': '10819E'}\n",
      "{'question': 'B5823+9136=', 'gen': '14959E'}\n",
      "{'question': 'B5197+8122=13319+6036=19355+5026=', 'gen': '24381E'}\n",
      "{'question': 'B4619+4586=9205+9146=', 'gen': '18351E'}\n",
      "{'question': 'B7590+472=8062+664=', 'gen': '8726E'}\n",
      "{'question': 'B530+8908=9438+4916=', 'gen': '14354E'}\n",
      "{'question': 'B1118+1419=2537+3398=5935+9187=', 'gen': '15122E'}\n"
     ]
    }
   ],
   "source": [
    "#====question====\n",
    "question = random.choices(dataset, k=8)\n",
    "question = [i['text'] for i in question]\n",
    "\n",
    "question = tokenizer(question,\n",
    "                     device=device,\n",
    "                     add_bos_token=True,\n",
    "                     add_eos_token=False,\n",
    "                     padding_side='left')['input_ids']\n",
    "\n",
    "#====gen====\n",
    "gen = generate(model_actor,\n",
    "               input_ids=question,\n",
    "               pad_token_id=tokenizer.pad_token_id,\n",
    "               eos_token_id=tokenizer.eos_token_id)\n",
    "gen = gen[:, question.shape[1]:]\n",
    "\n",
    "last_index = lambda lst, ele: len(lst) - lst[::-1].index(ele)\n",
    "\n",
    "for q, g in zip(question, gen):\n",
    "    q = tokenizer.decode(q)\n",
    "    g = tokenizer.decode(g)\n",
    "\n",
    "    print({'question': q, 'gen': g})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba42f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ''\n",
    "\n",
    "\n",
    "def inference(q):\n",
    "    global sent\n",
    "\n",
    "    sent += q + '='\n",
    "\n",
    "    #限制最大轮次\n",
    "    if sent.count('=') > 3:\n",
    "        idx = sent.index('=') + 1\n",
    "        sent = sent[idx:]\n",
    "\n",
    "    #编码\n",
    "    q = tokenizer([sent],\n",
    "                  device=device,\n",
    "                  add_bos_token=True,\n",
    "                  add_eos_token=False)['input_ids']\n",
    "\n",
    "    #生成回答\n",
    "    gen = generate(model_actor,\n",
    "                   input_ids=q,\n",
    "                   pad_token_id=tokenizer.pad_token_id,\n",
    "                   eos_token_id=tokenizer.eos_token_id)\n",
    "    gen = gen[:, q.shape[1]:][0].tolist()\n",
    "\n",
    "    #切除eos\n",
    "    if tokenizer.eos_token_id in gen:\n",
    "        idx = gen.index(tokenizer.eos_token_id)\n",
    "        gen = gen[:idx]\n",
    "\n",
    "    #如果生成了多余的对话,切除\n",
    "    if tokenizer.eq_token_id in gen:\n",
    "        idx = gen.index(tokenizer.eq_token_id)\n",
    "        gen = gen[:idx]\n",
    "\n",
    "    gen = tokenizer.decode(gen)\n",
    "\n",
    "    #拼接上下文\n",
    "    sent += gen\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "inference('1000+1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e7c83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2500'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('+500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1394a1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('+500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e2316c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3500'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('+500')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
