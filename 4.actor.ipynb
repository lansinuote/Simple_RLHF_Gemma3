{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec54a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tokenizer at 0x7fa62c3dc520>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "%run 1.tokenizer.ipynb\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267552ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62500,\n",
       " {'input_ids': tensor([[ 0,  8,  7,  6,  6, 14,  8, 13, 13,  8, 18, 13,  7,  5, 10,  1,  2],\n",
       "          [ 0,  5, 12, 11,  7, 14, 10, 13,  9, 11, 18, 12, 12,  7,  4,  1,  2],\n",
       "          [ 0, 11,  6, 10, 14, 12, 13,  4,  4, 18, 13, 10,  6, 10,  1,  2,  2],\n",
       "          [ 0,  8, 13,  4, 12, 14, 13,  6,  6, 13, 18,  5,  8,  5,  7, 11,  1],\n",
       "          [ 0, 10,  7,  9, 13, 14, 12,  6, 10,  8, 18,  5,  8, 10,  6,  7,  1],\n",
       "          [ 0,  7, 12,  9, 14,  6,  7, 11,  4, 18,  6, 11,  9,  9,  1,  2,  2],\n",
       "          [ 0, 10, 12, 11,  7, 14,  8,  8,  7,  4, 18,  5,  5,  7,  4,  7,  1],\n",
       "          [ 0,  5,  6,  5,  7, 14,  6, 13,  7,  9, 18,  8,  5,  8, 12,  1,  2],\n",
       "          [ 0,  8, 12, 10, 14, 13,  5, 10, 11, 18, 13, 10,  9,  7,  1,  2,  2],\n",
       "          [ 0, 13,  7,  7, 13, 14,  9,  8, 13, 12, 18,  5,  8, 12,  7, 11,  1],\n",
       "          [ 0,  9, 11,  6, 14,  6,  7, 12,  5, 18,  6, 13,  9,  7,  1,  2,  2],\n",
       "          [ 0, 13,  8,  7, 12, 14, 10, 11, 11,  4, 18,  5, 10,  6,  4, 12,  1],\n",
       "          [ 0, 11, 11, 12,  7, 14,  7,  4, 10,  9, 18,  5,  4, 12,  8, 12,  1],\n",
       "          [ 0,  9, 10, 12,  9, 14,  6,  9,  5,  7, 18, 12,  5, 13, 12,  1,  2],\n",
       "          [ 0,  5,  5, 11, 10, 14, 11, 10, 10, 13, 18, 12, 12,  8,  9,  1,  2],\n",
       "          [ 0,  5, 10, 11,  7, 14, 10,  7,  9,  9, 18, 12,  4,  6, 12,  1,  2]],\n",
       "         device='cuda:0'),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0'),\n",
       "  'labels': tensor([[   0,    8,    7,    6,    6,   14,    8,   13,   13,    8,   18,   13,\n",
       "              7,    5,   10,    1, -100],\n",
       "          [   0,    5,   12,   11,    7,   14,   10,   13,    9,   11,   18,   12,\n",
       "             12,    7,    4,    1, -100],\n",
       "          [   0,   11,    6,   10,   14,   12,   13,    4,    4,   18,   13,   10,\n",
       "              6,   10,    1, -100, -100],\n",
       "          [   0,    8,   13,    4,   12,   14,   13,    6,    6,   13,   18,    5,\n",
       "              8,    5,    7,   11,    1],\n",
       "          [   0,   10,    7,    9,   13,   14,   12,    6,   10,    8,   18,    5,\n",
       "              8,   10,    6,    7,    1],\n",
       "          [   0,    7,   12,    9,   14,    6,    7,   11,    4,   18,    6,   11,\n",
       "              9,    9,    1, -100, -100],\n",
       "          [   0,   10,   12,   11,    7,   14,    8,    8,    7,    4,   18,    5,\n",
       "              5,    7,    4,    7,    1],\n",
       "          [   0,    5,    6,    5,    7,   14,    6,   13,    7,    9,   18,    8,\n",
       "              5,    8,   12,    1, -100],\n",
       "          [   0,    8,   12,   10,   14,   13,    5,   10,   11,   18,   13,   10,\n",
       "              9,    7,    1, -100, -100],\n",
       "          [   0,   13,    7,    7,   13,   14,    9,    8,   13,   12,   18,    5,\n",
       "              8,   12,    7,   11,    1],\n",
       "          [   0,    9,   11,    6,   14,    6,    7,   12,    5,   18,    6,   13,\n",
       "              9,    7,    1, -100, -100],\n",
       "          [   0,   13,    8,    7,   12,   14,   10,   11,   11,    4,   18,    5,\n",
       "             10,    6,    4,   12,    1],\n",
       "          [   0,   11,   11,   12,    7,   14,    7,    4,   10,    9,   18,    5,\n",
       "              4,   12,    8,   12,    1],\n",
       "          [   0,    9,   10,   12,    9,   14,    6,    9,    5,    7,   18,   12,\n",
       "              5,   13,   12,    1, -100],\n",
       "          [   0,    5,    5,   11,   10,   14,   11,   10,   10,   13,   18,   12,\n",
       "             12,    8,    9,    1, -100],\n",
       "          [   0,    5,   10,   11,    7,   14,   10,    7,    9,    9,   18,   12,\n",
       "              4,    6,   12,    1, -100]], device='cuda:0')})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 2.dataset.ipynb\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    data = [i['text'] for i in data]\n",
    "    data = tokenizer(data, device=device)\n",
    "\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "    select = data['labels'] == tokenizer.pad_token_id\n",
    "    data['labels'][select] = -100\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "loader = get_loader(f, negative_label=False, with_answer=True)\n",
    "\n",
    "len(loader), next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8425c570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.01442304"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 3.model.ipynb\n",
    "\n",
    "model_actor = Gemma3Actor(len(tokenizer), tokenizer.pad_token_id).to(device)\n",
    "\n",
    "sum(i.numel() for i in model_actor.parameters()) / 1_0000_0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c532eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 62500 3.2236034870147705\n",
      "{'prompt': 'B120+7047=', 'chosen': '7167E', 'gen': 'B46B46B46B46B4'}\n",
      "1000 62500 1.8045706748962402\n",
      "{'prompt': 'B3684+5756=', 'chosen': '9440E', 'gen': '10000E'}\n",
      "2000 62500 1.661000370979309\n",
      "{'prompt': 'B6385+4142=', 'chosen': '10527E', 'gen': '10311E'}\n",
      "3000 62500 1.6442676782608032\n",
      "{'prompt': 'B5813+8349=', 'chosen': '14162E', 'gen': '14023E'}\n",
      "4000 62500 1.5948718786239624\n",
      "{'prompt': 'B4606+7036=', 'chosen': '11642E', 'gen': '11582E'}\n",
      "5000 62500 1.5552464723587036\n",
      "{'prompt': 'B8374+1550=', 'chosen': '9924E', 'gen': '9924E'}\n",
      "6000 62500 1.3911489248275757\n",
      "{'prompt': 'B5577+8832=', 'chosen': '14409E', 'gen': '14409E'}\n",
      "7000 62500 1.360396385192871\n",
      "{'prompt': 'B9739+2684=', 'chosen': '12423E', 'gen': '12423E'}\n",
      "8000 62500 1.2600985765457153\n",
      "{'prompt': 'B1153+5148=', 'chosen': '6301E', 'gen': '6301E'}\n",
      "9000 62500 1.306397557258606\n",
      "{'prompt': 'B6867+73=', 'chosen': '6940E', 'gen': '6330E'}\n",
      "10000 62500 1.2741001844406128\n",
      "{'prompt': 'B3473+510=', 'chosen': '3983E', 'gen': '3858E'}\n",
      "11000 62500 1.3037413358688354\n",
      "{'prompt': 'B5656+6867=', 'chosen': '12523E', 'gen': '12523E'}\n",
      "12000 62500 1.2315095663070679\n",
      "{'prompt': 'B6819+8774=', 'chosen': '15593E', 'gen': '15593E'}\n",
      "13000 62500 1.2540748119354248\n",
      "{'prompt': 'B6559+7731=', 'chosen': '14290E', 'gen': '14290E'}\n",
      "14000 62500 1.2665950059890747\n",
      "{'prompt': 'B7800+3166=', 'chosen': '10966E', 'gen': '10966E'}\n",
      "15000 62500 1.347639560699463\n",
      "{'prompt': 'B5504+2269=', 'chosen': '7773E', 'gen': '7773E'}\n",
      "16000 62500 1.2575767040252686\n",
      "{'prompt': 'B254+4796=', 'chosen': '5050E', 'gen': '5050E'}\n",
      "17000 62500 1.2859363555908203\n",
      "{'prompt': 'B2469+1516=', 'chosen': '3985E', 'gen': '3985E'}\n",
      "18000 62500 1.2475978136062622\n",
      "{'prompt': 'B303+7761=', 'chosen': '8064E', 'gen': '8064E'}\n",
      "19000 62500 1.2993576526641846\n",
      "{'prompt': 'B1525+34=', 'chosen': '1559E', 'gen': '1000E'}\n",
      "20000 62500 1.2381616830825806\n",
      "{'prompt': 'B622+7856=', 'chosen': '8478E', 'gen': '8478E'}\n",
      "21000 62500 1.194466233253479\n",
      "{'prompt': 'B9149+3065=', 'chosen': '12214E', 'gen': '12214E'}\n",
      "22000 62500 1.2082233428955078\n",
      "{'prompt': 'B314+5667=', 'chosen': '5981E', 'gen': '5981E'}\n",
      "23000 62500 1.272998571395874\n",
      "{'prompt': 'B6819+549=', 'chosen': '7368E', 'gen': '7368E'}\n",
      "24000 62500 1.181857705116272\n",
      "{'prompt': 'B7848+8713=', 'chosen': '16561E', 'gen': '16561E'}\n",
      "25000 62500 1.3216845989227295\n",
      "{'prompt': 'B2160+9207=', 'chosen': '11367E', 'gen': '11367E'}\n",
      "26000 62500 1.210209608078003\n",
      "{'prompt': 'B6479+8912=', 'chosen': '15391E', 'gen': '15391E'}\n",
      "27000 62500 1.2098792791366577\n",
      "{'prompt': 'B4478+5879=', 'chosen': '10357E', 'gen': '10357E'}\n",
      "28000 62500 1.2416325807571411\n",
      "{'prompt': 'B4631+2124=', 'chosen': '6755E', 'gen': '6755E'}\n",
      "29000 62500 1.2288779020309448\n",
      "{'prompt': 'B6169+4794=', 'chosen': '10963E', 'gen': '10963E'}\n",
      "30000 62500 1.2062345743179321\n",
      "{'prompt': 'B9762+1533=', 'chosen': '11295E', 'gen': '11295E'}\n",
      "31000 62500 1.2406718730926514\n",
      "{'prompt': 'B8284+2110=', 'chosen': '10394E', 'gen': '10394E'}\n",
      "32000 62500 1.204952359199524\n",
      "{'prompt': 'B3048+8161=', 'chosen': '11209E', 'gen': '11209E'}\n",
      "33000 62500 1.2493393421173096\n",
      "{'prompt': 'B234+9467=', 'chosen': '9701E', 'gen': '9701E'}\n",
      "34000 62500 1.206742286682129\n",
      "{'prompt': 'B9395+2279=', 'chosen': '11674E', 'gen': '11674E'}\n",
      "35000 62500 1.1791431903839111\n",
      "{'prompt': 'B9186+2434=', 'chosen': '11620E', 'gen': '11620E'}\n",
      "36000 62500 1.208179235458374\n",
      "{'prompt': 'B2256+5538=', 'chosen': '7794E', 'gen': '7794E'}\n",
      "37000 62500 1.2115119695663452\n",
      "{'prompt': 'B1976+8234=', 'chosen': '10210E', 'gen': '10210E'}\n",
      "38000 62500 1.2677903175354004\n",
      "{'prompt': 'B8726+36=', 'chosen': '8762E', 'gen': '8808E'}\n",
      "39000 62500 1.2037749290466309\n",
      "{'prompt': 'B3089+7389=', 'chosen': '10478E', 'gen': '10478E'}\n",
      "40000 62500 1.25030517578125\n",
      "{'prompt': 'B335+395=', 'chosen': '730E', 'gen': '826E'}\n",
      "41000 62500 1.19875168800354\n",
      "{'prompt': 'B4871+5877=', 'chosen': '10748E', 'gen': '10748E'}\n",
      "42000 62500 1.21539306640625\n",
      "{'prompt': 'B6766+2613=', 'chosen': '9379E', 'gen': '9379E'}\n",
      "43000 62500 1.219019889831543\n",
      "{'prompt': 'B2005+8250=', 'chosen': '10255E', 'gen': '10255E'}\n",
      "44000 62500 1.2380344867706299\n",
      "{'prompt': 'B5541+5929=', 'chosen': '11470E', 'gen': '11470E'}\n",
      "45000 62500 1.1838411092758179\n",
      "{'prompt': 'B9204+1560=', 'chosen': '10764E', 'gen': '10764E'}\n",
      "46000 62500 1.1865862607955933\n",
      "{'prompt': 'B1018+7735=', 'chosen': '8753E', 'gen': '8753E'}\n",
      "47000 62500 1.2129331827163696\n",
      "{'prompt': 'B6268+3186=', 'chosen': '9454E', 'gen': '9454E'}\n",
      "48000 62500 1.2215064764022827\n",
      "{'prompt': 'B7192+3487=', 'chosen': '10679E', 'gen': '10679E'}\n",
      "49000 62500 1.2112276554107666\n",
      "{'prompt': 'B4566+7733=', 'chosen': '12299E', 'gen': '12299E'}\n",
      "50000 62500 1.219362497329712\n",
      "{'prompt': 'B6094+9756=', 'chosen': '15850E', 'gen': '15850E'}\n",
      "51000 62500 1.2279473543167114\n",
      "{'prompt': 'B3117+1538=', 'chosen': '4655E', 'gen': '4655E'}\n",
      "52000 62500 1.2284932136535645\n",
      "{'prompt': 'B8458+5915=', 'chosen': '14373E', 'gen': '14373E'}\n",
      "53000 62500 1.2114630937576294\n",
      "{'prompt': 'B2468+8792=', 'chosen': '11260E', 'gen': '11260E'}\n",
      "54000 62500 1.2400457859039307\n",
      "{'prompt': 'B6777+8466=', 'chosen': '15243E', 'gen': '15243E'}\n",
      "55000 62500 1.2490878105163574\n",
      "{'prompt': 'B5961+739=', 'chosen': '6700E', 'gen': '6700E'}\n",
      "56000 62500 1.193254828453064\n",
      "{'prompt': 'B3499+8893=', 'chosen': '12392E', 'gen': '12392E'}\n",
      "57000 62500 1.185846209526062\n",
      "{'prompt': 'B3999+7728=', 'chosen': '11727E', 'gen': '11727E'}\n",
      "58000 62500 1.2061351537704468\n",
      "{'prompt': 'B4108+3799=', 'chosen': '7907E', 'gen': '7907E'}\n",
      "59000 62500 1.2256319522857666\n",
      "{'prompt': 'B1122+1530=', 'chosen': '2652E', 'gen': '2652E'}\n",
      "60000 62500 1.2275974750518799\n",
      "{'prompt': 'B6417+6571=', 'chosen': '12988E', 'gen': '12988E'}\n",
      "61000 62500 1.1982601881027222\n",
      "{'prompt': 'B1394+4323=', 'chosen': '5717E', 'gen': '5717E'}\n",
      "62000 62500 1.1769746541976929\n",
      "{'prompt': 'B9148+6612=', 'chosen': '15760E', 'gen': '15760E'}\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_actor.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,\n",
    "                                              base_lr=1e-5,\n",
    "                                              max_lr=1e-4,\n",
    "                                              step_size_up=1000)\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    loss, _ = model_actor(**data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, len(loader), loss.item())\n",
    "        prompt = data['input_ids'][0]\n",
    "        eq = prompt.tolist().index(tokenizer.eq_token_id) + 1\n",
    "        chosen = prompt[eq:]\n",
    "        prompt = prompt[:eq]\n",
    "\n",
    "        gen = generate(model_actor,\n",
    "                       input_ids=prompt.unsqueeze(0),\n",
    "                       pad_token_id=tokenizer.pad_token_id,\n",
    "                       eos_token_id=tokenizer.eos_token_id)\n",
    "        gen = gen[0, eq:]\n",
    "\n",
    "        print({\n",
    "            'prompt': tokenizer.decode(prompt),\n",
    "            'chosen': tokenizer.decode(chosen),\n",
    "            'gen': tokenizer.decode(gen)\n",
    "        })\n",
    "\n",
    "torch.save(model_actor.to('cpu'), 'model/actor')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
