{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec54a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tokenizer at 0x7f8055e48520>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "%run 1.tokenizer.ipynb\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847c02a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62500,\n",
       " {'input_ids': tensor([[ 0,  5,  6, 10,  6, 14,  7,  9, 11,  8, 18, 12, 12,  8,  5,  1,  2],\n",
       "          [ 0,  9,  8, 13,  8, 14, 12, 13,  9,  4, 18,  5,  8,  8,  8,  8,  1],\n",
       "          [ 0,  5, 10,  5,  6, 14,  5,  7,  8, 10, 18,  6, 13,  9, 12,  1,  2],\n",
       "          [ 0, 11,  8,  6, 10, 14, 12, 12,  7, 13, 18,  5, 10,  6, 10,  9,  1],\n",
       "          [ 0,  5, 10, 11, 10, 14, 10, 12,  7,  5, 18, 10,  8,  8, 12,  1,  2],\n",
       "          [ 0, 13,  9,  7,  9, 14, 12, 13, 12,  5, 18,  5,  6,  9, 10, 11,  1],\n",
       "          [ 0,  8, 11,  5, 12, 14,  7,  6,  7, 18,  9,  4,  8,  5,  1,  2,  2],\n",
       "          [ 0,  8,  9,  8,  6, 14, 13,  8, 13, 10, 18,  5,  8,  4,  7, 12,  1],\n",
       "          [ 0,  5, 13, 10,  9, 14,  5, 12,  6, 11, 18,  5,  4,  9,  8,  4,  1],\n",
       "          [ 0, 13,  9,  5,  9, 14,  8, 10, 10, 13, 18,  5,  8,  5, 12,  8,  1],\n",
       "          [ 0,  5, 11, 12,  6, 14,  7,  8, 11,  8, 18,  9,  6,  9, 10,  1,  2],\n",
       "          [ 0,  7, 12, 12, 13, 14,  9,  7,  6,  4, 18, 13,  6,  4, 13,  1,  2],\n",
       "          [ 0, 10,  7, 13,  4, 14, 12,  7, 13,  6, 18,  5,  8, 11, 12,  6,  1],\n",
       "          [ 0,  8,  5,  4,  5, 14,  8,  7,  4, 13, 18, 12,  8,  5,  4,  1,  2],\n",
       "          [ 0, 11, 12,  5, 11, 14,  6,  9,  8, 11, 18,  6, 11,  5,  5,  5,  1],\n",
       "          [ 0,  5, 10,  5,  6, 14,  9, 13,  6, 10, 18,  5,  5, 12,  9, 12,  1]],\n",
       "         device='cuda:0'),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'),\n",
       "  'labels': tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.],\n",
       "         device='cuda:0')})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 2.dataset.ipynb\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    text = [i['text'] for i in data]\n",
    "    label = [i['label'] for i in data]\n",
    "\n",
    "    data = tokenizer(text, device=device)\n",
    "    data['labels'] = torch.FloatTensor(label).to(device)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "loader = get_loader(f, negative_label=True, with_answer=True)\n",
    "\n",
    "len(loader), next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628012d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.01422848"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 3.model.ipynb\n",
    "\n",
    "model_critic = Gemma3Critic(len(tokenizer), tokenizer.pad_token_id,\n",
    "                            tokenizer.eos_token_id).to(device)\n",
    "\n",
    "sum(i.numel() for i in model_critic.parameters()) / 1_0000_0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d000bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 62500 0.6568640470504761 0.625\n",
      "1000 62500 0.22538667917251587 0.5625\n",
      "2000 62500 0.15205013751983643 0.75\n",
      "3000 62500 0.2514706254005432 0.625\n",
      "4000 62500 0.13919974863529205 0.8125\n",
      "5000 62500 0.17328010499477386 0.75\n",
      "6000 62500 0.1473165601491928 0.8125\n",
      "7000 62500 0.01866268552839756 1.0\n",
      "8000 62500 0.09422843158245087 0.875\n",
      "9000 62500 0.2106718122959137 0.75\n",
      "10000 62500 0.15441328287124634 0.8125\n",
      "11000 62500 0.04718015715479851 0.9375\n",
      "12000 62500 0.03505060821771622 0.9375\n",
      "13000 62500 0.05470049008727074 1.0\n",
      "14000 62500 0.05251363664865494 0.9375\n",
      "15000 62500 0.12895986437797546 0.8125\n",
      "16000 62500 0.08369071781635284 0.8125\n",
      "17000 62500 0.15602001547813416 0.8125\n",
      "18000 62500 0.04057002067565918 0.9375\n",
      "19000 62500 0.04003428667783737 1.0\n",
      "20000 62500 0.06784521788358688 0.875\n",
      "21000 62500 0.06001725792884827 0.875\n",
      "22000 62500 0.0022971846628934145 1.0\n",
      "23000 62500 0.06056694686412811 0.9375\n",
      "24000 62500 0.05474509671330452 0.9375\n",
      "25000 62500 0.022833609953522682 1.0\n",
      "26000 62500 0.057579100131988525 0.9375\n",
      "27000 62500 0.0707215666770935 0.875\n",
      "28000 62500 0.012757215648889542 1.0\n",
      "29000 62500 0.07069322466850281 0.875\n",
      "30000 62500 0.05862724035978317 0.9375\n",
      "31000 62500 0.05568867176771164 0.9375\n",
      "32000 62500 0.0822673887014389 0.875\n",
      "33000 62500 0.01528190914541483 1.0\n",
      "34000 62500 0.06363971531391144 0.9375\n",
      "35000 62500 0.04168281704187393 0.9375\n",
      "36000 62500 0.029670752584934235 0.9375\n",
      "37000 62500 0.012490556575357914 1.0\n",
      "38000 62500 0.061523690819740295 0.9375\n",
      "39000 62500 0.06426110118627548 0.875\n",
      "40000 62500 0.05165883153676987 0.9375\n",
      "41000 62500 0.010520795360207558 1.0\n",
      "42000 62500 0.003164740977808833 1.0\n",
      "43000 62500 0.05376182124018669 0.875\n",
      "44000 62500 0.039460327476263046 0.9375\n",
      "45000 62500 0.036423277109861374 1.0\n",
      "46000 62500 0.07597151398658752 0.875\n",
      "47000 62500 0.046733930706977844 0.9375\n",
      "48000 62500 0.03142423555254936 0.9375\n",
      "49000 62500 0.05826088786125183 0.9375\n",
      "50000 62500 0.05733821541070938 0.9375\n",
      "51000 62500 0.03415118157863617 0.9375\n",
      "52000 62500 0.13361480832099915 0.875\n",
      "53000 62500 0.017727453261613846 1.0\n",
      "54000 62500 0.02900032512843609 0.9375\n",
      "55000 62500 0.12663769721984863 0.8125\n",
      "56000 62500 0.048118188977241516 0.9375\n",
      "57000 62500 0.0050066192634403706 1.0\n",
      "58000 62500 0.0013353772228583694 1.0\n",
      "59000 62500 0.06249110400676727 0.875\n",
      "60000 62500 0.0029855321627110243 1.0\n",
      "61000 62500 0.1641893982887268 0.8125\n",
      "62000 62500 0.040668975561857224 0.9375\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_critic.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,\n",
    "                                              base_lr=1e-5,\n",
    "                                              max_lr=1e-4,\n",
    "                                              step_size_up=1000)\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    loss, logits = model_critic(**data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        logits = (logits > 0.5).squeeze(1).long()\n",
    "        acc = (logits == data['labels'].long()).sum() / len(data['labels'])\n",
    "        print(i, len(loader), loss.item(), acc.item())\n",
    "\n",
    "torch.save(model_critic.to('cpu'), 'model/critic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
