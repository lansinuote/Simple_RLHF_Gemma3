{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec54a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tokenizer at 0x7f459de34550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "%run 1.tokenizer.ipynb\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847c02a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62500,\n",
       " {'input_ids': tensor([[ 0, 13, 12,  4,  6, 14, 10,  8,  6, 11, 18,  5, 10,  6, 12, 13,  1,  2,\n",
       "            2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0,  6, 13, 12, 11, 14, 10,  8,  9,  4, 18, 13,  8,  7, 11, 14, 13,  7,\n",
       "            7, 18,  5,  4,  7, 11,  4, 14, 13,  7,  5,  8, 18,  5, 13, 11,  4, 13,\n",
       "            1,  2,  2],\n",
       "          [ 0,  8,  4,  4, 11, 14,  5, 13, 10,  5, 18,  9, 13, 10, 12, 14,  8, 12,\n",
       "           13,  8, 18,  5,  4, 13, 10,  9,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0,  7,  8, 13, 10, 14,  9,  4,  4,  4, 18, 12,  8, 13, 10, 14,  7,  8,\n",
       "           13, 12, 18,  5,  6,  5,  6,  6,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0,  5,  5,  7, 11, 14,  8,  9,  4, 18,  5,  9, 12, 11, 14, 10,  8,  7,\n",
       "           12, 18, 12,  4,  6,  9,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0,  9,  4, 12,  9, 14, 12, 12, 12, 13, 18,  5,  7, 13, 11,  8, 14,  7,\n",
       "            5,  4,  8, 18,  5, 11,  4, 11, 12, 14,  5,  8, 10, 11, 18,  5, 12, 10,\n",
       "           12,  6,  1],\n",
       "          [ 0,  7,  5, 13,  8, 14,  9,  6, 11, 11, 18, 12,  8, 11,  5, 14, 12, 10,\n",
       "            7,  7, 18,  5, 11,  6,  6, 11,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0,  9,  5,  7,  8, 14, 11, 10, 12,  8, 18,  5,  6, 12,  5, 12, 14, 13,\n",
       "            8, 13,  5, 18,  6,  6,  7,  4, 13, 14,  5,  4, 10, 18,  6,  6,  5, 13,\n",
       "           13,  1,  2],\n",
       "          [ 0,  8, 12,  9,  6, 14,  8, 13, 13,  5, 18, 13, 12,  8,  7,  1,  2,  2,\n",
       "            2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0, 13, 13,  7, 11, 14,  7, 12, 11,  5, 18,  5,  7, 12,  4, 12, 14,  8,\n",
       "            7,  9, 18,  5,  8,  6,  8,  7, 14, 12,  7, 10,  5, 18,  6,  6,  8, 11,\n",
       "            7,  1,  2],\n",
       "          [ 0,  8,  6, 10,  4, 14,  8, 10,  8,  4, 18, 12, 13,  4,  4,  1,  2,  2,\n",
       "            2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0,  7,  4,  4, 13, 14, 10, 13,  7, 12, 18, 13, 13,  8, 11, 14,  7, 12,\n",
       "            5,  8, 18,  5,  7, 10, 13, 10,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0, 12,  7,  4,  7, 14, 10, 11,  4,  9, 18,  5,  9,  4,  4, 12, 14,  7,\n",
       "           13, 12, 11, 18,  5, 13,  5,  5,  5,  1,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0,  9, 11,  8, 13, 14, 10,  7, 11,  8, 18,  5,  6,  5,  6,  7,  1,  2,\n",
       "            2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2],\n",
       "          [ 0, 13, 13,  9, 14, 13, 10, 11,  4, 18,  5,  4, 10, 10,  9, 14, 11, 10,\n",
       "           11, 18,  5,  5,  8,  7,  6, 14,  6,  9, 12,  4, 18,  5,  7, 13, 12,  4,\n",
       "            1,  2,  2],\n",
       "          [ 0,  9,  5, 13,  9, 14,  8,  4, 13, 10, 18, 13,  5,  9,  9,  1,  2,  2,\n",
       "            2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "            2,  2,  2]], device='cuda:0'),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'),\n",
       "  'labels': tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.],\n",
       "         device='cuda:0')})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 2.dataset.ipynb\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    text = [i['text'] for i in data]\n",
    "    label = [i['label'] for i in data]\n",
    "\n",
    "    data = tokenizer(text, device=device)\n",
    "    data['labels'] = torch.FloatTensor(label).to(device)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "loader = get_loader(f, negative_label=True, with_answer=True)\n",
    "\n",
    "len(loader), next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628012d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.01422848"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run 3.model.ipynb\n",
    "\n",
    "model_critic = Gemma3Critic(len(tokenizer), tokenizer.pad_token_id,tokenizer.eos_token_id).to(device)\n",
    "#model_critic = torch.load('model/critic', weights_only=False).to(device)\n",
    "\n",
    "sum(i.numel() for i in model_critic.parameters()) / 1_0000_0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d000bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4070695638656616 0.375\n",
      "1000 0.38209378719329834 0.25\n",
      "2000 0.25080031156539917 0.4375\n",
      "3000 0.24669183790683746 0.5625\n",
      "4000 0.2549736201763153 0.375\n",
      "5000 0.24508115649223328 0.5625\n",
      "6000 0.25359800457954407 0.25\n",
      "7000 0.24961596727371216 0.625\n",
      "8000 0.24944931268692017 0.5625\n",
      "9000 0.26551973819732666 0.4375\n",
      "10000 0.2512258291244507 0.4375\n",
      "11000 0.30359578132629395 0.5\n",
      "12000 0.2586905062198639 0.375\n",
      "13000 0.2434312105178833 0.625\n",
      "14000 0.2505418062210083 0.5\n",
      "15000 0.2539946734905243 0.5\n",
      "16000 0.2564588785171509 0.4375\n",
      "17000 0.2804393172264099 0.4375\n",
      "18000 0.249833345413208 0.5\n",
      "19000 0.24675226211547852 0.5625\n",
      "20000 0.2516259253025055 0.375\n",
      "21000 0.2735432982444763 0.3125\n",
      "22000 0.25803452730178833 0.375\n",
      "23000 0.2546844482421875 0.375\n",
      "24000 0.248661071062088 0.5625\n",
      "25000 0.24559956789016724 0.5625\n",
      "26000 0.24690701067447662 0.6875\n",
      "27000 0.24715930223464966 0.625\n",
      "28000 0.24775150418281555 0.625\n",
      "29000 0.2503160536289215 0.5625\n",
      "30000 0.2540351152420044 0.375\n",
      "31000 0.2560177147388458 0.375\n",
      "32000 0.25208646059036255 0.375\n",
      "33000 0.2522987127304077 0.375\n",
      "34000 0.248747780919075 0.5625\n",
      "35000 0.277671754360199 0.25\n",
      "36000 0.2532394230365753 0.375\n",
      "37000 0.2645794749259949 0.25\n",
      "38000 0.2522902488708496 0.4375\n",
      "39000 0.22795715928077698 0.6875\n",
      "40000 0.2504993975162506 0.5\n",
      "41000 0.24801868200302124 0.625\n",
      "42000 0.24760045111179352 0.6875\n",
      "43000 0.24694585800170898 0.75\n",
      "44000 0.24473027884960175 0.625\n",
      "45000 0.22193560004234314 0.75\n",
      "46000 0.24871870875358582 0.5\n",
      "47000 0.23617002367973328 0.625\n",
      "48000 0.2522481083869934 0.375\n",
      "49000 0.2510274350643158 0.4375\n",
      "50000 0.24807412922382355 0.5625\n",
      "51000 0.2415246069431305 0.625\n",
      "52000 0.25088217854499817 0.4375\n",
      "53000 0.2647998631000519 0.4375\n",
      "54000 0.2571958899497986 0.375\n",
      "55000 0.2494485229253769 0.4375\n",
      "56000 0.24743056297302246 0.5625\n",
      "57000 0.2716320753097534 0.3125\n",
      "58000 0.2582020163536072 0.375\n",
      "59000 0.2827149033546448 0.375\n",
      "60000 0.2381616234779358 0.6875\n",
      "61000 0.2158624231815338 0.6875\n",
      "62000 0.2563735246658325 0.3125\n",
      "63000 0.27744540572166443 0.375\n",
      "64000 0.24366921186447144 0.6875\n",
      "65000 0.24754229187965393 0.5\n",
      "66000 0.2484239786863327 0.5625\n",
      "67000 0.25323161482810974 0.5\n",
      "68000 0.2522660493850708 0.5\n",
      "69000 0.24911615252494812 0.5625\n",
      "70000 0.25729089975357056 0.4375\n",
      "71000 0.24724039435386658 0.5\n",
      "72000 0.2615177631378174 0.4375\n",
      "73000 0.26102733612060547 0.375\n",
      "74000 0.25552958250045776 0.5625\n",
      "75000 0.25879740715026855 0.375\n",
      "76000 0.2527875006198883 0.4375\n",
      "77000 0.25659945607185364 0.375\n",
      "78000 0.24611181020736694 0.4375\n",
      "79000 0.23149484395980835 0.6875\n",
      "80000 0.2655239701271057 0.375\n",
      "81000 0.25380977988243103 0.4375\n",
      "82000 0.2499821037054062 0.5625\n",
      "83000 0.25200581550598145 0.5\n",
      "84000 0.24717235565185547 0.5625\n",
      "85000 0.23605412244796753 0.6875\n",
      "86000 0.2453988790512085 0.5\n",
      "87000 0.2332022488117218 0.6875\n",
      "88000 0.26764917373657227 0.3125\n",
      "89000 0.2697175145149231 0.375\n",
      "90000 0.24208803474903107 0.4375\n",
      "91000 0.2581905722618103 0.4375\n",
      "92000 0.24818329513072968 0.4375\n",
      "93000 0.22072580456733704 0.75\n",
      "94000 0.25617116689682007 0.5625\n",
      "95000 0.23873011767864227 0.5\n",
      "96000 0.2492937296628952 0.5\n",
      "97000 0.2437329888343811 0.5625\n",
      "98000 0.22916093468666077 0.8125\n",
      "99000 0.2619715929031372 0.375\n",
      "100000 0.24996259808540344 0.375\n",
      "101000 0.2683451771736145 0.25\n",
      "102000 0.25470632314682007 0.4375\n",
      "103000 0.27777013182640076 0.375\n",
      "104000 0.23402881622314453 0.5\n",
      "105000 0.24995654821395874 0.5625\n",
      "106000 0.2116842269897461 0.6875\n",
      "107000 0.2579808831214905 0.4375\n",
      "108000 0.23682226240634918 0.5\n",
      "109000 0.23957206308841705 0.4375\n",
      "110000 0.25370994210243225 0.375\n",
      "111000 0.25187623500823975 0.625\n",
      "112000 0.22869598865509033 0.5625\n",
      "113000 0.2521982789039612 0.4375\n",
      "114000 0.2468380481004715 0.375\n",
      "115000 0.23289713263511658 0.5625\n",
      "116000 0.2298383265733719 0.4375\n",
      "117000 0.27721473574638367 0.4375\n",
      "118000 0.2315399944782257 0.6875\n",
      "119000 0.24402852356433868 0.4375\n",
      "120000 0.2090110182762146 0.6875\n",
      "121000 0.21658538281917572 0.5625\n",
      "122000 0.24589873850345612 0.5\n",
      "123000 0.22675083577632904 0.6875\n",
      "124000 0.2495487928390503 0.5625\n",
      "125000 0.23403829336166382 0.5625\n",
      "126000 0.17862668633460999 0.75\n",
      "127000 0.2110789716243744 0.6875\n",
      "128000 0.2783505320549011 0.4375\n",
      "129000 0.2454589605331421 0.5\n",
      "130000 0.23073546588420868 0.75\n",
      "131000 0.17988479137420654 0.75\n",
      "132000 0.2242020070552826 0.5625\n",
      "133000 0.2098015695810318 0.6875\n",
      "134000 0.21070608496665955 0.6875\n",
      "135000 0.23239222168922424 0.4375\n",
      "136000 0.18942882120609283 0.75\n",
      "137000 0.2280551940202713 0.5625\n",
      "138000 0.18854467570781708 0.6875\n",
      "139000 0.16122223436832428 0.75\n",
      "140000 0.13091112673282623 0.8125\n",
      "141000 0.2717322111129761 0.375\n",
      "142000 0.19580814242362976 0.6875\n",
      "143000 0.16065850853919983 0.75\n",
      "144000 0.11315912753343582 0.875\n",
      "145000 0.20855003595352173 0.625\n",
      "146000 0.13377000391483307 0.875\n",
      "147000 0.13476820290088654 0.8125\n",
      "148000 0.12285468727350235 0.8125\n",
      "149000 0.06854850798845291 0.9375\n",
      "150000 0.05804978311061859 1.0\n",
      "151000 0.2193119376897812 0.8125\n",
      "152000 0.13145753741264343 0.875\n",
      "153000 0.1519305258989334 0.75\n",
      "154000 0.05788279324769974 1.0\n",
      "155000 0.2142680138349533 0.75\n",
      "156000 0.12298297882080078 0.9375\n",
      "157000 0.09991064667701721 0.875\n",
      "158000 0.1608600914478302 0.75\n",
      "159000 0.10789290815591812 0.8125\n",
      "160000 0.11180827021598816 0.875\n",
      "161000 0.11516834050416946 0.9375\n",
      "162000 0.0916280597448349 0.9375\n",
      "163000 0.08008898794651031 0.875\n",
      "164000 0.17196327447891235 0.75\n",
      "165000 0.23758810758590698 0.6875\n",
      "166000 0.2009328007698059 0.75\n",
      "167000 0.1735101044178009 0.875\n",
      "168000 0.04792096093297005 0.9375\n",
      "169000 0.11351708322763443 0.8125\n",
      "170000 0.1399831622838974 0.8125\n",
      "171000 0.14477980136871338 0.8125\n",
      "172000 0.07991814613342285 0.9375\n",
      "173000 0.1112399697303772 0.8125\n",
      "174000 0.07057712972164154 0.9375\n",
      "175000 0.12116468697786331 0.875\n",
      "176000 0.07724460959434509 0.9375\n",
      "177000 0.08961758762598038 0.9375\n",
      "178000 0.1372341513633728 0.8125\n",
      "179000 0.02289886772632599 1.0\n",
      "180000 0.09144969284534454 0.875\n",
      "181000 0.026678578928112984 1.0\n",
      "182000 0.042272575199604034 0.9375\n",
      "183000 0.12826086580753326 0.8125\n",
      "184000 0.15688949823379517 0.8125\n",
      "185000 0.02732030674815178 1.0\n",
      "186000 0.06831099092960358 0.9375\n",
      "187000 0.12533098459243774 0.8125\n",
      "188000 0.08529234677553177 0.9375\n",
      "189000 0.1932724416255951 0.6875\n",
      "190000 0.12564155459403992 0.875\n",
      "191000 0.0832623690366745 0.875\n",
      "192000 0.07067850232124329 0.875\n",
      "193000 0.13583604991436005 0.8125\n",
      "194000 0.011840909719467163 1.0\n",
      "195000 0.026516884565353394 1.0\n",
      "196000 0.02930387668311596 0.9375\n",
      "197000 0.0503358468413353 0.9375\n",
      "198000 0.18449124693870544 0.75\n",
      "199000 0.13012415170669556 0.875\n",
      "200000 0.027616243809461594 0.9375\n",
      "201000 0.10925951600074768 0.8125\n",
      "202000 0.09768408536911011 0.875\n",
      "203000 0.07428798079490662 0.9375\n",
      "204000 0.09419149905443192 0.875\n",
      "205000 0.1243334487080574 0.8125\n",
      "206000 0.05330304056406021 0.9375\n",
      "207000 0.10282295942306519 0.8125\n",
      "208000 0.009120753966271877 1.0\n",
      "209000 0.08860649913549423 0.8125\n",
      "210000 0.06962490826845169 0.875\n",
      "211000 0.029107145965099335 0.9375\n",
      "212000 0.026595575734972954 1.0\n",
      "213000 0.13324573636054993 0.875\n",
      "214000 0.006677382159978151 1.0\n",
      "215000 0.1432998776435852 0.875\n",
      "216000 0.0789436623454094 0.9375\n",
      "217000 0.05425079166889191 0.875\n",
      "218000 0.153665691614151 0.8125\n",
      "219000 0.047493867576122284 0.9375\n",
      "220000 0.04677436500787735 0.9375\n",
      "221000 0.08709914982318878 0.9375\n",
      "222000 0.11806292831897736 0.75\n",
      "223000 0.07590951770544052 0.9375\n",
      "224000 0.03649793565273285 0.9375\n",
      "225000 0.22863921523094177 0.6875\n",
      "226000 0.1927882730960846 0.75\n",
      "227000 0.01851177215576172 1.0\n",
      "228000 0.07514592260122299 0.875\n",
      "229000 0.03806820511817932 0.9375\n",
      "230000 0.16801199316978455 0.8125\n",
      "231000 0.016588635742664337 1.0\n",
      "232000 0.193722203373909 0.75\n",
      "233000 0.0737931877374649 0.9375\n",
      "234000 0.009101425297558308 1.0\n",
      "235000 0.0762997716665268 0.9375\n",
      "236000 0.07960604131221771 0.875\n",
      "237000 0.05865936353802681 0.9375\n",
      "238000 0.11337053775787354 0.875\n",
      "239000 0.061874471604824066 0.9375\n",
      "240000 0.06138009577989578 0.9375\n",
      "241000 0.06439781188964844 0.9375\n",
      "242000 0.06218069791793823 0.9375\n",
      "243000 0.17810583114624023 0.75\n",
      "244000 0.058499954640865326 0.9375\n",
      "245000 0.1099688708782196 0.875\n",
      "246000 0.059238679707050323 0.9375\n",
      "247000 0.12360639870166779 0.8125\n",
      "248000 0.023201745003461838 1.0\n",
      "249000 0.10746201872825623 0.875\n",
      "250000 0.09712239354848862 0.875\n",
      "251000 0.01598343998193741 1.0\n",
      "252000 0.05805281549692154 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253000 0.0532238744199276 0.9375\n",
      "254000 0.061535656452178955 0.9375\n",
      "255000 0.24492290616035461 0.6875\n",
      "256000 0.0774487555027008 0.875\n",
      "257000 0.06755175441503525 0.9375\n",
      "258000 0.06499262899160385 0.875\n",
      "259000 0.12868434190750122 0.8125\n",
      "260000 0.00470309890806675 1.0\n",
      "261000 0.08985453099012375 0.875\n",
      "262000 0.1072244793176651 0.875\n",
      "263000 0.052289895713329315 0.9375\n",
      "264000 0.07268092781305313 0.9375\n",
      "265000 0.006905793212354183 1.0\n",
      "266000 0.007543587125837803 1.0\n",
      "267000 0.05773168429732323 0.9375\n",
      "268000 0.08362363278865814 0.875\n",
      "269000 0.1362980306148529 0.8125\n",
      "270000 0.02100067026913166 1.0\n",
      "271000 0.06300139427185059 0.9375\n",
      "272000 0.019401244819164276 0.9375\n",
      "273000 0.03244801238179207 0.9375\n",
      "274000 0.05958474427461624 0.9375\n",
      "275000 0.09385383129119873 0.875\n",
      "276000 0.13079625368118286 0.8125\n",
      "277000 0.0077892797999084 1.0\n",
      "278000 0.003704980481415987 1.0\n",
      "279000 0.057150889188051224 0.9375\n",
      "280000 0.005467685405164957 1.0\n",
      "281000 0.1163824275135994 0.8125\n",
      "282000 0.0032481704838573933 1.0\n",
      "283000 0.006088267080485821 1.0\n",
      "284000 0.12880124151706696 0.875\n",
      "285000 0.1635230928659439 0.8125\n",
      "286000 0.1067076176404953 0.875\n",
      "287000 0.11737503111362457 0.8125\n",
      "288000 0.08716439455747604 0.875\n",
      "289000 0.012231561355292797 1.0\n",
      "290000 0.06132262945175171 0.9375\n",
      "291000 0.1148584634065628 0.875\n",
      "292000 0.05556795746088028 0.9375\n",
      "293000 0.10123047232627869 0.875\n",
      "294000 0.10495075583457947 0.8125\n",
      "295000 0.16036084294319153 0.8125\n",
      "296000 0.07383398711681366 0.875\n",
      "297000 0.02449212409555912 1.0\n",
      "298000 0.0709867924451828 0.9375\n",
      "299000 0.01684892177581787 1.0\n",
      "300000 0.007300341036170721 1.0\n",
      "301000 0.05456671491265297 0.9375\n",
      "302000 0.11884279549121857 0.875\n",
      "303000 0.05167649686336517 0.9375\n",
      "304000 0.13887886703014374 0.8125\n",
      "305000 0.07597227394580841 0.875\n",
      "306000 0.01038707047700882 1.0\n",
      "307000 0.0601106621325016 0.9375\n",
      "308000 0.009135882370173931 1.0\n",
      "309000 0.01743752509355545 1.0\n",
      "310000 0.012447606772184372 1.0\n",
      "311000 0.006078494247049093 1.0\n",
      "312000 0.11136201024055481 0.8125\n",
      "313000 0.012131696566939354 1.0\n",
      "314000 0.060058124363422394 0.9375\n",
      "315000 0.005932705942541361 1.0\n",
      "316000 0.01866965927183628 1.0\n",
      "317000 0.06936384737491608 0.9375\n",
      "318000 0.1558106243610382 0.8125\n",
      "319000 0.03893134742975235 0.9375\n",
      "320000 0.10430003702640533 0.875\n",
      "321000 0.13307048380374908 0.875\n",
      "322000 0.09967208653688431 0.8125\n",
      "323000 0.008893518708646297 1.0\n",
      "324000 0.055716902017593384 0.9375\n",
      "325000 0.011026975698769093 1.0\n",
      "326000 0.10287807881832123 0.875\n",
      "327000 0.09523513913154602 0.875\n",
      "328000 0.005730419419705868 1.0\n",
      "329000 0.059054166078567505 0.9375\n",
      "330000 0.1351856291294098 0.8125\n",
      "331000 0.07163211703300476 0.875\n",
      "332000 0.003945472184568644 1.0\n",
      "333000 0.06455183029174805 0.9375\n",
      "334000 0.05567112937569618 0.9375\n",
      "335000 0.0016877971356734633 1.0\n",
      "336000 0.004589110612869263 1.0\n",
      "337000 0.0617675743997097 0.9375\n",
      "338000 0.054584141820669174 0.9375\n",
      "339000 0.07151588797569275 0.875\n",
      "340000 0.056998200714588165 0.9375\n",
      "341000 0.015131100080907345 1.0\n",
      "342000 0.04484470933675766 0.9375\n",
      "343000 0.046276576817035675 0.875\n",
      "344000 0.009100258350372314 1.0\n",
      "345000 0.011648312211036682 1.0\n",
      "346000 0.11386992037296295 0.875\n",
      "347000 0.019667135551571846 1.0\n",
      "348000 0.05601467564702034 0.9375\n",
      "349000 0.03504414111375809 0.9375\n",
      "350000 0.05930681899189949 0.9375\n",
      "351000 0.004496553912758827 1.0\n",
      "352000 0.04257115349173546 0.9375\n",
      "353000 0.055600348860025406 0.9375\n",
      "354000 0.004683510400354862 1.0\n",
      "355000 0.008440201170742512 1.0\n",
      "356000 0.054167553782463074 0.9375\n",
      "357000 0.03431648015975952 0.9375\n",
      "358000 0.004344699904322624 1.0\n",
      "359000 0.062238629907369614 0.9375\n",
      "360000 0.056612059473991394 0.9375\n",
      "361000 0.008666731417179108 1.0\n",
      "362000 0.05575023964047432 0.9375\n",
      "363000 0.13116203248500824 0.8125\n",
      "364000 0.0027573974803090096 1.0\n",
      "365000 0.04811849445104599 0.9375\n",
      "366000 0.06013176962733269 0.9375\n",
      "367000 0.009451876394450665 1.0\n",
      "368000 0.007793819066137075 1.0\n",
      "369000 0.014764413237571716 1.0\n",
      "370000 0.10435852408409119 0.875\n",
      "371000 0.05998780205845833 0.9375\n",
      "372000 0.0032065664418041706 1.0\n",
      "373000 0.06475163996219635 0.9375\n",
      "374000 0.0257728174328804 1.0\n",
      "375000 0.060533300042152405 0.9375\n",
      "376000 0.007678997237235308 1.0\n",
      "377000 0.014921018853783607 1.0\n",
      "378000 0.05582564324140549 0.9375\n",
      "379000 0.06913871318101883 0.9375\n",
      "380000 0.07718242704868317 0.875\n",
      "381000 0.05306905880570412 0.9375\n",
      "382000 0.005916687194257975 1.0\n",
      "383000 0.017871715128421783 0.9375\n",
      "384000 0.060068245977163315 0.9375\n",
      "385000 0.10483278334140778 0.875\n",
      "386000 0.01822187379002571 1.0\n",
      "387000 0.06642647087574005 0.9375\n",
      "388000 0.0056569501757621765 1.0\n",
      "389000 0.06471707671880722 0.9375\n",
      "390000 0.004203055985271931 1.0\n",
      "391000 0.08060850203037262 0.875\n",
      "392000 0.10572479665279388 0.875\n",
      "393000 0.0028705429285764694 1.0\n",
      "394000 0.05410148948431015 0.9375\n",
      "395000 0.0032990830950438976 1.0\n",
      "396000 0.002747542457655072 1.0\n",
      "397000 0.12898105382919312 0.8125\n",
      "398000 0.10774657875299454 0.875\n",
      "399000 0.054488807916641235 0.9375\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_critic.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,\n",
    "                                              base_lr=1e-5,\n",
    "                                              max_lr=1e-4,\n",
    "                                              step_size_up=1000)\n",
    "\n",
    "for epoch in range(40_0000):\n",
    "    data = next(iter(loader))\n",
    "\n",
    "    loss, logits = model_critic(**data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        logits = (logits > 0.5).squeeze(1).long()\n",
    "        acc = (logits == data['labels'].long()).sum() / len(data['labels'])\n",
    "        print(epoch, loss.item(), acc.item())\n",
    "\n",
    "torch.save(model_critic.to('cpu'), 'model/critic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
